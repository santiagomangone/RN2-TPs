{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdMUpBztATQz7+MGqD3x4f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagomangone/RN2-TPs/blob/main/TP3%20-%20LM/RN2_LM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabajo Práctico Redes Neuronales 2 - Language Models\n",
        "El presente trabajo tiene como objetivo el armado de un modelo de lenguaje, probando y comparando diferentes arquitecturas para hacer un analisis sobre la performance de cada uno de ellos"
      ],
      "metadata": {
        "id": "lAKYS95WLc_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fuentes\n",
        "Las fuentes consultadas en complemento con las clases de la materia serán añadidas en esta celda. A saber, se utilizaron como referencia:\n",
        "\n",
        "Video ilustrativo y muy útil para entender de que va la cosa: [1] https://www.youtube.com/watch?v=ZMudJXhsUpY&list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S&index=7\n",
        "\n",
        "\n",
        "Artículos de contexto para la temática de modelos de lenguaje: [2] https://developers.google.com/machine-learning/resources/intro-llms?hl=es-419#:~:text=A%20language%20model%20is%20a,a%20longer%20sequence%20of%20tokens.\n",
        "\n",
        "[3] https://builtin.com/data-science/beginners-guide-language-models\n",
        "\n",
        "Fuente proveída por la catedra para elegir una metrica para evaluar los modelos generativos: [4] https://towardsdatascience.com/how-to-evaluate-text-generation-models-metrics-for-automatic-evaluation-of-nlp-models-e1c251b04ec1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5kbBR8h1Lw7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jbbjx9lVSfWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e97f6a-d99f-4303-db8a-5cfb4c4d30f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Texto base\n",
        "El texto base elegido para entrenar los modelos es la novela corta de Franz Kafka, \"La Metamorfósis\"\n"
      ],
      "metadata": {
        "id": "Y8LYYT0ANfpy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "M8EkOJ1DrBTi",
        "outputId": "c09373d5-ca63-454a-c776-39ddc6a104d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'< eran las seis y media y las manecillas seguían tranquilamente hacia delante, ya había pasado incluso la media, eran ya casi las menos cuarto. «¿es que no habría sonado el despertador?» desde la cama se veía que estaba correctamente puesto a las cuatro, seguro que también había sonado. sí, pero... ¿era posible seguir durmiendo tan tranquilo con ese ruido que hacía temblar los muebles? bueno, tampoco había dormido tranquilo, pero quizá tanto más profundamente. >'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#traemos la data, la segmentamos, separamos, preparamos\n",
        "#reverse_dictionary = token.index_word\n",
        "#dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])\n",
        "TXTDIR= \"/content/drive/MyDrive/Colab Notebooks/La Metamorfosis.txt\"\n",
        "\n",
        "with open(TXTDIR, 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "parrafos = text.lower().split('\\n\\n') # Divido el contenido en parrafos y paso las letras a minúsculas.\n",
        "\n",
        "# Eliminamos enters y agregamos SOS y EOS\n",
        "dataset = [\"< \"+parrafo.strip().replace('\\n', ' ')+\" >\" for parrafo in parrafos if parrafo !=\"\"]\n",
        "dataset[11]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pequeño EDA.\n",
        "Como separamos el texto en parrafos que seran las entradas para el entrenamiento de los modelos, es util saber cuantos tenemos y que tan largos suelen ser los parrafos. Además es útil saber con cuantas palabras cuenta nuestra dataset."
      ],
      "metadata": {
        "id": "W3KZTOgh2cUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_size=len(dataset)\n",
        "print(\"Cantidad de parrafos: \",corpus_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P42_r_aPTwF5",
        "outputId": "592f2a5c-5959-4659-dc13-8351b6895459"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de parrafos:  193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "longitudes = [len(texto.split()) for texto in dataset]\n",
        "\n",
        "bin_edges = plt.hist(longitudes, bins=10, edgecolor='k', alpha=0.7)\n",
        "plt.xticks([50,120,200,300,400,800], ['50','120','200','300','400','800'])\n",
        "\n",
        "plt.title('Longitudes de Parrafos')\n",
        "plt.xlabel('Longitud')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tbqLJvcNT-GR",
        "outputId": "bb85adbd-d7a6-48d0-93cc-2745ed911a1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenización"
      ],
      "metadata": {
        "id": "LZScOIcVjTVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividimos las oraciones en palabras\n",
        "words = [word for sentence in dataset for word in sentence.split()]\n",
        "#nos quedamos con las palabras unicas\n",
        "unique_words = set(words)\n",
        "\n",
        "num_words = len(unique_words)\n",
        "\n",
        "print(f\"Cantidad de palabras únicas: {num_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Yg7zkL7fFpm",
        "outputId": "4cb1917b-22f1-4cc3-a44f-913d3b5df4bc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de palabras únicas: 4660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import plot_model, to_categorical, pad_sequences\n",
        "\n",
        "token=Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n¡-¿»«—', lower=True, split=' ', char_level=False, oov_token=\"UNK\", document_count=0) #Instanciamos el tokenizador\n",
        "token.fit_on_texts(dataset)                                                                                                                                 # y fiteamos a nuestro dataset\n",
        "\n",
        "dictionary = token.index_word\n",
        "vocab_size=len(dictionary)+1\n",
        "print(\"Luego de removidos signos de puntuacion, la cantidad real de palabras a tokenizar es:\", vocab_size)"
      ],
      "metadata": {
        "id": "bkiAdo-weoKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75282c1-292e-4850-bd8b-497dc931a490"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Luego de removidos signos de puntuacion, la cantidad real de palabras a tokenizar es: 3501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "id": "YewfGlebjHpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genero secuencias para el entrenamiento. Para ello tomo oraciones, las tokenizo, y armo dos listas, una que contenga una oracion menos su ultima palabra y la otra con la palabra que iría a continuación. Esto es similar al caso de tener data con sus respectivos labels. A la vez aprovecho y padeo las secuencias para que tengan el mismo tamaño, y las palabras de salida o labels paso a representarlos como una categoría (one-hot encoding). Con esta idea notamos que para los modelos que se entrenan aqui la dimension de entrada es fija."
      ],
      "metadata": {
        "id": "VvNAMjMukMR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_seqs = token.texts_to_sequences(dataset)  # Tokenizo los textos\n",
        "max_len=500                                         #Del EDA notamos que los parrafos son de hasta 500 palabras en su gran mayoría, por eso tomamos de tamaño maximo de largo de contexto 500.\n",
        "x_sequences = []\n",
        "y_sequences = []\n",
        "for text in tokenized_seqs:\n",
        "  for i in range(1,len(text)):\n",
        "      x_sequences.append(text[:i])  # Arreglos de entrada\n",
        "      y_sequences.append(text[i])   # Arreglos de salida\n",
        "x_sequences = pad_sequences(x_sequences, maxlen=max_len, padding='pre', truncating='pre')\n",
        "y_sequences = to_categorical(y_sequences, num_classes=len(token.index_word)+1)              #Al usar one-hot, usaremos como loss Categorical-Cross\n",
        "\n"
      ],
      "metadata": {
        "id": "-xqeKZBZknLe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_sequences.shape)\n",
        "print(y_sequences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IfwMSXv3cEB",
        "outputId": "99d1a51a-fbca-4b6a-a04f-b103c02523c2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20612, 500)\n",
            "(20612, 3501)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizemos una\n",
        "print(\"Para la oracion:\")\n",
        "print(token.sequences_to_texts([x_sequences[13][-6:]])[0])\n",
        "print(\"La siguiente palabra sería:\")\n",
        "print(token.index_word[(np.argmax(y_sequences[13]))])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfQDVvMfm7Gt",
        "outputId": "86a19fbe-ab4e-47be-8fa7-f2bb251dbf05"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para la oracion:\n",
            "después de un sueño intranquilo se\n",
            "La siguiente palabra sería:\n",
            "encontró\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargamos embeddings pre entrenados\n",
        "Cargamos los embeddings que provee fasttext para el idioma español"
      ],
      "metadata": {
        "id": "5ksUdBt0npOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "#load embeddings\n",
        "EMBEDDING_DIR = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(EMBEDDING_DIR+'cc.es.300.vec', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45K4SMsVjb8t",
        "outputId": "ccb918f9-04a7-414c-da67-5b5a19af84e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n",
            "found 2000000 word vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teniendo los embeddings para las 2M de palabras, ahora procedemos a armar nuestra matriz de embeddings, es decir, nos quedamos con las palabras que figuran en nuestro texto y les damos sus significados semánticos extraidos segun fastText.\n",
        "\n",
        "Mas info sobre estos en: https://fasttext.cc/docs/en/crawl-vectors.html"
      ],
      "metadata": {
        "id": "cqljZcea3b_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 300\n",
        "embedding_matrix = np.zeros([vocab_size, embed_dim])\n",
        "for idx, word in dictionary.items():\n",
        "    if idx < vocab_size and word in embeddings_index:\n",
        "        embedding_matrix[idx,:] = embeddings_index[word]"
      ],
      "metadata": {
        "id": "Lte09MKT2NJy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métricas\n",
        "En cuanto a las metricas de evaluación mas relevantes para el analisis de performance se consideraron las mencionadas en la fuente referenciada mas arriba, a saber:\n",
        "\n",
        "Consultando con otros grupos se decidió utilizar la metrica de perplejidad, la cual conceptualmente tiene mucho sentido ya que plantea alimentar al modelo con oraciones reales propias del set de datos y promediar las probabilidades de que acierte correctamente la \"respuesta correcta\", en este caso la siguiente palabra"
      ],
      "metadata": {
        "id": "sTKQO7iP9uql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(model, x_sequences, y_indices, nwords, embedding_matrix):\n",
        "    perp = np.array([])\n",
        "\n",
        "    for i in range(len(x_sequences)):\n",
        "        x_seq = x_sequences[i]\n",
        "        y_idx = y_indices[i]\n",
        "\n",
        "        predicted_probs = model.predict(np.array([x_seq]), verbose=0)[0]\n",
        "\n",
        "        word_prob = predicted_probs[y_idx]\n",
        "\n",
        "        #sequence_perplexity = 2 ** (-np.log2(word_prob))\n",
        "        sequence_perplexity = 1 / word_prob\n",
        "        perp = np.append(perp, sequence_perplexity)\n",
        "\n",
        "    mean_perplexity = np.mean(perp)\n",
        "\n",
        "    return mean_perplexity"
      ],
      "metadata": {
        "id": "FJbHtg3XpvIV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos\n",
        "Con los datos listos, estamos en condiciones de definir nuestros modelos"
      ],
      "metadata": {
        "id": "u2mQzp5h02zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, BatchNormalization, GlobalMaxPooling1D, Dropout, Dense, Lambda, MaxPooling1D, Input, Concatenate, SimpleRNN, Dot, RepeatVector, TimeDistributed, Multiply, Lambda, Flatten, Activation, GRU, Reshape, Bidirectional, LSTM\n",
        "from keras.layers import Input, Concatenate, Dot, RepeatVector, TimeDistributed, Multiply\n",
        "from keras.layers import Bidirectional, LSTM, Activation, Reshape, Lambda, Dropout, GRU\n",
        "from keras.models import Sequential, Model\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.activations import softmax\n",
        "import keras.backend as K\n",
        "from keras.utils import plot_model\n",
        "\n",
        "def softMaxOverTime(x):\n",
        "    return tf.keras.activations.softmax(x,axis=1)"
      ],
      "metadata": {
        "id": "9Ks1HrAD1LpK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) LSTM"
      ],
      "metadata": {
        "id": "zHbP76SB05GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_dim=100\n",
        "#vocab_size =3k+ =Cantidad de palabras en mi vocabulario\n",
        "#Max_len = 500, tamaño del contexto\n",
        "embed_dim = 300\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(vocab_size, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "#LSTM\n",
        "lstm_out = Bidirectional(LSTM(LSTM_dim, return_sequences=True, activation=\"tanh\"), merge_mode=\"sum\")(embedding_layer)\n",
        "ulog_attention = Dense(1, activation=\"linear\")(lstm_out)\n",
        "\n",
        "attention=Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention = TimeDistributed(RepeatVector(LSTM_dim))(attention)\n",
        "repeated_attention = Reshape([max_len, LSTM_dim])(repeated_attention)\n",
        "\n",
        "weighted_embeddings = Multiply()([repeated_attention, lstm_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n",
        "\n",
        "dense1 = Dense(256, activation='relu')(embedding_sum)\n",
        "dense2 = Dense(128, activation='relu')(dense1)\n",
        "dense_out = Dense(vocab_size, activation='softmax')(dense2)              #Elige entre las 3k palabras posibles\n",
        "\n",
        "modelLSTM = Model(input_layer, dense_out)\n",
        "adam = optimizers.Adam(learning_rate=0.01)\n",
        "modelLSTM.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['categorical_crossentropy'])\n",
        "modelLSTM.summary()"
      ],
      "metadata": {
        "id": "7eogvSR61bYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e511d009-11c6-400b-d175-5774c814e413"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_16 (InputLayer)       [(None, 500)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding_13 (Embedding)    (None, 500, 300)             1050300   ['input_16[0][0]']            \n",
            "                                                                                                  \n",
            " bidirectional_11 (Bidirect  (None, 500, 100)             320800    ['embedding_13[0][0]']        \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " dense_34 (Dense)            (None, 500, 1)               101       ['bidirectional_11[0][0]']    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)  (None, 500, 1)               0         ['dense_34[0][0]']            \n",
            "                                                                                                  \n",
            " time_distributed_13 (TimeD  (None, 500, 100, 1)          0         ['activation_13[0][0]']       \n",
            " istributed)                                                                                      \n",
            "                                                                                                  \n",
            " reshape_7 (Reshape)         (None, 500, 100)             0         ['time_distributed_13[0][0]'] \n",
            "                                                                                                  \n",
            " multiply_11 (Multiply)      (None, 500, 100)             0         ['reshape_7[0][0]',           \n",
            "                                                                     'bidirectional_11[0][0]']    \n",
            "                                                                                                  \n",
            " lambda_7 (Lambda)           (None, 100)                  0         ['multiply_11[0][0]']         \n",
            "                                                                                                  \n",
            " dense_35 (Dense)            (None, 256)                  25856     ['lambda_7[0][0]']            \n",
            "                                                                                                  \n",
            " dense_36 (Dense)            (None, 128)                  32896     ['dense_35[0][0]']            \n",
            "                                                                                                  \n",
            " dense_37 (Dense)            (None, 3501)                 451629    ['dense_36[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1881582 (7.18 MB)\n",
            "Trainable params: 831282 (3.17 MB)\n",
            "Non-trainable params: 1050300 (4.01 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.callbacks as callbacks\n",
        "#Defino callbacks utiles\n",
        "early_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=5,\n",
        "                                   start_from_epoch=12)\n",
        "\n",
        "plateu_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.05,\n",
        "                                          patience=3)\n"
      ],
      "metadata": {
        "id": "fEWZXOLy3W17"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = modelLSTM.fit(x=x_sequences,y=y_sequences,batch_size=256,epochs=40,validation_split=0.1, callbacks = [early_cb, plateau_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYXvkD9zEquT",
        "outputId": "43f9df3f-4585-488d-8bf1-2f014bf75f87"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "73/73 [==============================] - 41s 493ms/step - loss: 6.5940 - categorical_crossentropy: 6.5940 - accuracy: 0.0453 - val_loss: 6.5420 - val_categorical_crossentropy: 6.5420 - val_accuracy: 0.0500 - lr: 0.0100\n",
            "Epoch 2/40\n",
            "73/73 [==============================] - 35s 489ms/step - loss: 6.1859 - categorical_crossentropy: 6.1859 - accuracy: 0.0490 - val_loss: 6.4970 - val_categorical_crossentropy: 6.4970 - val_accuracy: 0.0538 - lr: 0.0100\n",
            "Epoch 3/40\n",
            "73/73 [==============================] - 32s 441ms/step - loss: 5.9567 - categorical_crossentropy: 5.9567 - accuracy: 0.0567 - val_loss: 6.4147 - val_categorical_crossentropy: 6.4147 - val_accuracy: 0.0567 - lr: 0.0100\n",
            "Epoch 4/40\n",
            "73/73 [==============================] - 36s 503ms/step - loss: 5.7696 - categorical_crossentropy: 5.7696 - accuracy: 0.0653 - val_loss: 6.3914 - val_categorical_crossentropy: 6.3914 - val_accuracy: 0.0587 - lr: 0.0100\n",
            "Epoch 5/40\n",
            "73/73 [==============================] - 36s 505ms/step - loss: 5.5562 - categorical_crossentropy: 5.5562 - accuracy: 0.0868 - val_loss: 6.2664 - val_categorical_crossentropy: 6.2664 - val_accuracy: 0.0713 - lr: 0.0100\n",
            "Epoch 6/40\n",
            "73/73 [==============================] - 33s 461ms/step - loss: 5.3526 - categorical_crossentropy: 5.3526 - accuracy: 0.0928 - val_loss: 6.2503 - val_categorical_crossentropy: 6.2503 - val_accuracy: 0.0752 - lr: 0.0100\n",
            "Epoch 7/40\n",
            "73/73 [==============================] - 38s 529ms/step - loss: 5.1998 - categorical_crossentropy: 5.1998 - accuracy: 0.1039 - val_loss: 6.1702 - val_categorical_crossentropy: 6.1702 - val_accuracy: 0.0829 - lr: 0.0100\n",
            "Epoch 8/40\n",
            "73/73 [==============================] - 32s 444ms/step - loss: 5.0616 - categorical_crossentropy: 5.0616 - accuracy: 0.1115 - val_loss: 6.3008 - val_categorical_crossentropy: 6.3008 - val_accuracy: 0.0868 - lr: 0.0100\n",
            "Epoch 9/40\n",
            "73/73 [==============================] - 33s 454ms/step - loss: 4.9317 - categorical_crossentropy: 4.9317 - accuracy: 0.1174 - val_loss: 6.3346 - val_categorical_crossentropy: 6.3346 - val_accuracy: 0.0989 - lr: 0.0100\n",
            "Epoch 10/40\n",
            "73/73 [==============================] - 36s 492ms/step - loss: 4.8153 - categorical_crossentropy: 4.8153 - accuracy: 0.1274 - val_loss: 6.4065 - val_categorical_crossentropy: 6.4065 - val_accuracy: 0.1018 - lr: 0.0100\n",
            "Epoch 11/40\n",
            "73/73 [==============================] - 35s 479ms/step - loss: 4.7037 - categorical_crossentropy: 4.7037 - accuracy: 0.1337 - val_loss: 6.4680 - val_categorical_crossentropy: 6.4680 - val_accuracy: 0.1038 - lr: 0.0100\n",
            "Epoch 12/40\n",
            "73/73 [==============================] - 30s 416ms/step - loss: 4.5768 - categorical_crossentropy: 4.5768 - accuracy: 0.1438 - val_loss: 6.6243 - val_categorical_crossentropy: 6.6243 - val_accuracy: 0.1096 - lr: 0.0100\n",
            "Epoch 13/40\n",
            "73/73 [==============================] - 37s 507ms/step - loss: 4.4479 - categorical_crossentropy: 4.4479 - accuracy: 0.1514 - val_loss: 6.8803 - val_categorical_crossentropy: 6.8803 - val_accuracy: 0.1081 - lr: 0.0100\n",
            "Epoch 14/40\n",
            "73/73 [==============================] - 38s 527ms/step - loss: 4.3179 - categorical_crossentropy: 4.3179 - accuracy: 0.1616 - val_loss: 6.9427 - val_categorical_crossentropy: 6.9427 - val_accuracy: 0.1077 - lr: 0.0100\n",
            "Epoch 15/40\n",
            "73/73 [==============================] - 34s 469ms/step - loss: 4.1813 - categorical_crossentropy: 4.1813 - accuracy: 0.1707 - val_loss: 7.2721 - val_categorical_crossentropy: 7.2721 - val_accuracy: 0.1091 - lr: 0.0100\n",
            "Epoch 16/40\n",
            "73/73 [==============================] - 34s 475ms/step - loss: 4.0429 - categorical_crossentropy: 4.0429 - accuracy: 0.1862 - val_loss: 7.3725 - val_categorical_crossentropy: 7.3725 - val_accuracy: 0.1101 - lr: 0.0100\n",
            "Epoch 17/40\n",
            "73/73 [==============================] - 40s 548ms/step - loss: 3.9201 - categorical_crossentropy: 3.9201 - accuracy: 0.1950 - val_loss: 7.7874 - val_categorical_crossentropy: 7.7874 - val_accuracy: 0.1101 - lr: 0.0100\n",
            "Epoch 18/40\n",
            "73/73 [==============================] - 31s 435ms/step - loss: 3.7738 - categorical_crossentropy: 3.7738 - accuracy: 0.2105 - val_loss: 8.0260 - val_categorical_crossentropy: 8.0260 - val_accuracy: 0.1081 - lr: 0.0100\n",
            "Epoch 19/40\n",
            "73/73 [==============================] - 37s 506ms/step - loss: 3.6599 - categorical_crossentropy: 3.6599 - accuracy: 0.2198 - val_loss: 8.4309 - val_categorical_crossentropy: 8.4309 - val_accuracy: 0.1052 - lr: 0.0100\n",
            "Epoch 20/40\n",
            "73/73 [==============================] - 36s 494ms/step - loss: 3.5367 - categorical_crossentropy: 3.5367 - accuracy: 0.2352 - val_loss: 8.6211 - val_categorical_crossentropy: 8.6211 - val_accuracy: 0.0994 - lr: 0.0100\n",
            "Epoch 21/40\n",
            "73/73 [==============================] - 37s 506ms/step - loss: 3.4091 - categorical_crossentropy: 3.4091 - accuracy: 0.2511 - val_loss: 9.1216 - val_categorical_crossentropy: 9.1216 - val_accuracy: 0.1062 - lr: 0.0100\n",
            "Epoch 22/40\n",
            "73/73 [==============================] - 38s 523ms/step - loss: 3.2856 - categorical_crossentropy: 3.2856 - accuracy: 0.2667 - val_loss: 9.5042 - val_categorical_crossentropy: 9.5042 - val_accuracy: 0.0994 - lr: 0.0100\n",
            "Epoch 23/40\n",
            "73/73 [==============================] - 37s 510ms/step - loss: 3.1735 - categorical_crossentropy: 3.1735 - accuracy: 0.2794 - val_loss: 9.8404 - val_categorical_crossentropy: 9.8404 - val_accuracy: 0.0989 - lr: 0.0100\n",
            "Epoch 24/40\n",
            "73/73 [==============================] - 40s 548ms/step - loss: 3.0533 - categorical_crossentropy: 3.0533 - accuracy: 0.3013 - val_loss: 10.1594 - val_categorical_crossentropy: 10.1594 - val_accuracy: 0.0955 - lr: 0.0100\n",
            "Epoch 25/40\n",
            "73/73 [==============================] - 29s 401ms/step - loss: 2.9673 - categorical_crossentropy: 2.9673 - accuracy: 0.3108 - val_loss: 10.4531 - val_categorical_crossentropy: 10.4531 - val_accuracy: 0.0955 - lr: 0.0100\n",
            "Epoch 26/40\n",
            "73/73 [==============================] - 32s 448ms/step - loss: 2.8693 - categorical_crossentropy: 2.8693 - accuracy: 0.3220 - val_loss: 11.2536 - val_categorical_crossentropy: 11.2536 - val_accuracy: 0.0975 - lr: 0.0100\n",
            "Epoch 27/40\n",
            "73/73 [==============================] - 41s 564ms/step - loss: 2.7593 - categorical_crossentropy: 2.7593 - accuracy: 0.3406 - val_loss: 11.6397 - val_categorical_crossentropy: 11.6397 - val_accuracy: 0.0873 - lr: 0.0100\n",
            "Epoch 28/40\n",
            "73/73 [==============================] - 45s 618ms/step - loss: 2.6566 - categorical_crossentropy: 2.6566 - accuracy: 0.3542 - val_loss: 11.8238 - val_categorical_crossentropy: 11.8238 - val_accuracy: 0.0854 - lr: 0.0100\n",
            "Epoch 29/40\n",
            "73/73 [==============================] - 37s 509ms/step - loss: 2.5778 - categorical_crossentropy: 2.5778 - accuracy: 0.3716 - val_loss: 12.4091 - val_categorical_crossentropy: 12.4091 - val_accuracy: 0.0834 - lr: 0.0100\n",
            "Epoch 30/40\n",
            "73/73 [==============================] - 39s 545ms/step - loss: 2.4980 - categorical_crossentropy: 2.4980 - accuracy: 0.3863 - val_loss: 12.6284 - val_categorical_crossentropy: 12.6284 - val_accuracy: 0.0839 - lr: 0.0100\n",
            "Epoch 31/40\n",
            "73/73 [==============================] - 35s 487ms/step - loss: 2.3784 - categorical_crossentropy: 2.3784 - accuracy: 0.4053 - val_loss: 13.3543 - val_categorical_crossentropy: 13.3543 - val_accuracy: 0.0824 - lr: 0.0100\n",
            "Epoch 32/40\n",
            "73/73 [==============================] - 38s 522ms/step - loss: 2.3060 - categorical_crossentropy: 2.3060 - accuracy: 0.4184 - val_loss: 13.7333 - val_categorical_crossentropy: 13.7333 - val_accuracy: 0.0824 - lr: 0.0100\n",
            "Epoch 33/40\n",
            "73/73 [==============================] - 34s 471ms/step - loss: 2.2572 - categorical_crossentropy: 2.2572 - accuracy: 0.4306 - val_loss: 13.5527 - val_categorical_crossentropy: 13.5527 - val_accuracy: 0.0834 - lr: 0.0100\n",
            "Epoch 34/40\n",
            "73/73 [==============================] - 31s 425ms/step - loss: 2.1683 - categorical_crossentropy: 2.1683 - accuracy: 0.4440 - val_loss: 14.2849 - val_categorical_crossentropy: 14.2849 - val_accuracy: 0.0810 - lr: 0.0100\n",
            "Epoch 35/40\n",
            "73/73 [==============================] - 40s 549ms/step - loss: 2.0506 - categorical_crossentropy: 2.0506 - accuracy: 0.4685 - val_loss: 14.5306 - val_categorical_crossentropy: 14.5306 - val_accuracy: 0.0732 - lr: 0.0100\n",
            "Epoch 36/40\n",
            "73/73 [==============================] - 38s 521ms/step - loss: 1.9681 - categorical_crossentropy: 1.9681 - accuracy: 0.4837 - val_loss: 15.2343 - val_categorical_crossentropy: 15.2343 - val_accuracy: 0.0781 - lr: 0.0100\n",
            "Epoch 37/40\n",
            "73/73 [==============================] - 30s 419ms/step - loss: 1.8873 - categorical_crossentropy: 1.8873 - accuracy: 0.4984 - val_loss: 15.9479 - val_categorical_crossentropy: 15.9479 - val_accuracy: 0.0829 - lr: 0.0100\n",
            "Epoch 38/40\n",
            "73/73 [==============================] - 41s 566ms/step - loss: 1.8308 - categorical_crossentropy: 1.8308 - accuracy: 0.5146 - val_loss: 16.4648 - val_categorical_crossentropy: 16.4648 - val_accuracy: 0.0747 - lr: 0.0100\n",
            "Epoch 39/40\n",
            "73/73 [==============================] - 32s 437ms/step - loss: 1.7593 - categorical_crossentropy: 1.7593 - accuracy: 0.5296 - val_loss: 16.7778 - val_categorical_crossentropy: 16.7778 - val_accuracy: 0.0776 - lr: 0.0100\n",
            "Epoch 40/40\n",
            "73/73 [==============================] - 39s 546ms/step - loss: 1.7063 - categorical_crossentropy: 1.7063 - accuracy: 0.5390 - val_loss: 17.2260 - val_categorical_crossentropy: 17.2260 - val_accuracy: 0.0713 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = perplexity(modelLSTM, x_sequences[:100], y_sequences[:100], vocab_size, embedding_matrix)\n",
        "print(\"Perplejidad del modelo:\", perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "MuAbMCBbp1Rr",
        "outputId": "b9fc52e3-19f4-4a58-b5ac-47e58799dadf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1c66fbd3b826>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Perplejidad del modelo:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'perplexity' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) CNN"
      ],
      "metadata": {
        "id": "6cKzG1Fr07yS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value_dim=100\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(vocab_size, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "#CNN\n",
        "cnn_out = (Conv1D(value_dim, kernel_size=3, activation=\"relu\", padding=\"same\"))(embedding_layer)\n",
        "ulog_attention = Dense(1, activation=\"linear\")(cnn_out)\n",
        "attention = Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention = TimeDistributed(RepeatVector(value_dim))(attention)\n",
        "repeated_attention = Reshape([max_len, value_dim])(repeated_attention)\n",
        "weighted_embeddings = Multiply()([repeated_attention, cnn_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n",
        "\n",
        "dense1 = Dense(256, activation='relu')(embedding_sum)\n",
        "dense2 = Dense(128, activation='relu')(dense1)\n",
        "dense_out = Dense(vocab_size, activation='softmax')(dense2)              #Elige entre las 3k palabras posibles\n",
        "\n",
        "modelCNN = Model(input_layer, dense2)\n",
        "adam = optimizers.Adam(learning_rate=0.01)\n",
        "modelCNN.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=adam,\n",
        "                 metrics=['categorical_crossentropy'])\n"
      ],
      "metadata": {
        "id": "8HRu2QRx3ysx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=5,\n",
        "                                   start_from_epoch=12)\n",
        "\n",
        "plateu_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.05,\n",
        "                                          patience=3)"
      ],
      "metadata": {
        "id": "8st3hgPhZKz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = modelCNN.fit(x_sequences,y_sequences,batch_size=256,epochs=40,validation_split=0.1, callbacks = [early_cb, plateau_cb])"
      ],
      "metadata": {
        "id": "vorRmkTRZMmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = perplexity(modelCNN, x_sequences[:100], y_sequences[:100], vocab_size, embedding_matrix)\n",
        "print(\"Perplejidad del modelo:\", perplexity)"
      ],
      "metadata": {
        "id": "UYiANX0np3Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) GRU"
      ],
      "metadata": {
        "id": "d2m8MjV71EQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value_dim=100\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(vocab_size, embed_dim, input_length=max_len, trainable=False)(input_layer)\n",
        "#GRU\n",
        "gru_out = Bidirectional(GRU(value_dim, return_sequences=True, activation=\"tanh\"), merge_mode=\"sum\")(embedding_layer)\n",
        "\n",
        "ulog_attention = Dense(1, activation=\"linear\")(gru_out)\n",
        "attention = Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention = TimeDistributed(RepeatVector(value_dim))(attention)\n",
        "repeated_attention = Reshape([max_len, value_dim])(repeated_attention)\n",
        "weighted_embeddings = Multiply()([repeated_attention, gru_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n",
        "\n",
        "dense1 = Dense(256, activation='relu')(embedding_sum)\n",
        "dense2 = Dense(128, activation='relu')(dense1)\n",
        "dense_out = Dense(vocab_size, activation='softmax')(dense2)              #Elige entre las 3k palabras posibles\n",
        "\n",
        "modelGRU = Model(input_layer, dense2)\n",
        "adam = optimizers.Adam(learning_rate=0.001)\n",
        "modelGRU.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=adam,\n",
        "                 metrics=['categorical_crossentropy'])"
      ],
      "metadata": {
        "id": "BGUG6BDx3v2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=5,\n",
        "                                   start_from_epoch=12)\n",
        "\n",
        "plateu_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.05,\n",
        "                                          patience=3)\n",
        "hist = modelGRU.fit(x_sequences,y_sequences,batch_size=256,epochs=40,validation_split=0.1, callbacks = [early_cb, plateau_cb])"
      ],
      "metadata": {
        "id": "WEiqjgD1ZOpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = perplexity(modelGRU, x_sequences[:100], y_sequences[:100], vocab_size, embedding_matrix)\n",
        "print(\"Perplejidad del modelo:\", perplexity)"
      ],
      "metadata": {
        "id": "Rh_ytLjBp497"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generación\n",
        "Se además de evaluar la metrica de perplejidad se probaron las capacidades de generacion de los 3 modelos entrenados. En este caso se probaron 2 funciones distintas, por un lado se tomó una implementación para el algoritmo \"Greedy Search\" y por otro \"Beam Search\".\n",
        "\n",
        "Una fuente que resultó útil para entenderlos fue: https://medium.com/@jessica_lopez/understanding-greedy-search-and-beam-search-98c1e3cd821d\n",
        "\n",
        "Las implementaciones presentadas en este trabajo fueron tomadas del grupo Basili-Wahle, quienes no solo accedieron a su uso sino que tambien colaboraron a su vez en entender algunas cuestiones particulares a las mismas."
      ],
      "metadata": {
        "id": "G-aWG1YX4B_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Greedy Search con Arg-Max"
      ],
      "metadata": {
        "id": "qcM3lotldfV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy(seed_phrase, token, model, pred_len=25, max_len=500, stopper=\"> sep\"):\n",
        "  stop_token = token.texts_to_sequences([stopper])[0]\n",
        "  seed_text = token.texts_to_sequences([seed_phrase])[0]\n",
        "  pred_arr = []\n",
        "\n",
        "  for _ in range(pred_len):\n",
        "    # Concatenamos y paddeamos\n",
        "    aux = np.concatenate((seed_text, pred_arr))\n",
        "    padded = pad_sequences([aux], maxlen=max_len)\n",
        "\n",
        "    # Predecimos\n",
        "    pred_idx = np.argmax(model.predict(padded, verbose=0)[0])\n",
        "\n",
        "    if pred_idx in stop_token:  # La prediccion hasta un stop_char\n",
        "      break\n",
        "\n",
        "    pred_arr = np.append(pred_arr, [int(pred_idx)])\n",
        "\n",
        "\n",
        "  return token.sequences_to_texts([pred_arr])[0]"
      ],
      "metadata": {
        "id": "r_OA_O2o04ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed= \"< el siguiente\"\n",
        "prediction = greedy(seed, token, model, pred_len=25)\n",
        "print(seed, prediction)"
      ],
      "metadata": {
        "id": "fZ156eHndttN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Greedy Search + Temperatura"
      ],
      "metadata": {
        "id": "3ywLKXBFdwcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def greedyTemp(seed_phrase, token, model, temp=1, pred_len=25, max_len=500, stopper=[\">\", \"sep\"]):\n",
        "  stop_token = token.texts_to_sequences(stopper)[0]\n",
        "  seed_text = token.texts_to_sequences([seed_phrase])[0]\n",
        "  pred_arr = []\n",
        "\n",
        "  for _ in range(pred_len):\n",
        "    # Concatenamos y paddeamos\n",
        "    aux = np.concatenate((seed_text, pred_arr))\n",
        "    padded = pad_sequences([aux], maxlen=max_len)\n",
        "\n",
        "    # Predecimos considerando temperatura y elegimos de forma semialeatoria\n",
        "    probs = (model.predict(padded, verbose=0)[0])**(1/temp)\n",
        "    pred_idx = random.choices(range(len(probs)), weights=probs, k=1)\n",
        "\n",
        "    if pred_idx in stop_token:\n",
        "      break\n",
        "\n",
        "    # Agregamos el nuevo token a la prediccion\n",
        "    pred_arr = np.append(pred_arr, [pred_idx])\n",
        "\n",
        "  return token.sequences_to_texts([pred_arr])[0]"
      ],
      "metadata": {
        "id": "KYabpkGidxod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed= \"< el siguiente\"\n",
        "prediction = greedyTemp(seed, token, model, temp=1.25, pred_len=25)\n",
        "print(seed, prediction)\n"
      ],
      "metadata": {
        "id": "vd9seoojd1_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stochastic Beam Search"
      ],
      "metadata": {
        "id": "GaPeQUw9d4dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def stochastic_beam_search(seed_phrase, token, n_beam=3, temp=1.0, pred_len=20):\n",
        "    seqs = token.texts_to_sequences([seed_phrase])\n",
        "    probs = [1]\n",
        "\n",
        "    for paso in range(pred_len):\n",
        "        new_seqs = []\n",
        "        new_probs = []\n",
        "\n",
        "        for i in range(len(seqs)):\n",
        "            padded = pad_sequences([seqs[i]], maxlen=max_len)\n",
        "            # Generar prediccion y aplicar temp\n",
        "            pred_probs = (model.predict(padded, verbose=0)[0])**(1/temp)\n",
        "\n",
        "            # Elegir N opciones en base a sus probs\n",
        "            pred_idx = random.choices(range(len(pred_probs)), weights=pred_probs, k=n_beam)\n",
        "\n",
        "            # Appendear token predichos y sus probs calculadas\n",
        "            for idx in pred_idx:\n",
        "              new_seqs.append(seqs[i]+[idx])\n",
        "              new_probs.append(probs[i]*pred_probs[idx])\n",
        "\n",
        "        # Actualizamos\n",
        "        seqs = new_seqs\n",
        "        probs = new_probs\n",
        "\n",
        "    likely_idx = probs.index(max(probs)) # Me quedo con la opcion mas probable\n",
        "\n",
        "    #Devuelvo la prediccion (sin la seed) en formato texto\n",
        "    return token.sequences_to_texts([seqs[likely_idx]])[0]"
      ],
      "metadata": {
        "id": "zdPjBSRQd-Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seed= \"< el siguiente\"\n",
        "prediction = stochastic_beam_search(seed, token, n_beam=3, temp=1, pred_len=5)\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "4xwt-eq4eBjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seed= \"< el siguiente\"\n",
        "prediction = stochastic_beam_search(seed, token, n_beam=3, temp=2, pred_len=5)      #Variamos la temperatura\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "QyIhDnWreB52"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}