{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagomangone/RN2-TPs/blob/main/TP3%20-%20LM/RN2_LM_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabajo Práctico Redes Neuronales 2 - Language Models\n",
        "El presente trabajo tiene como objetivo el armado de un modelo de lenguaje, probando y comparando diferentes arquitecturas para hacer un analisis sobre la performance de cada uno de ellos"
      ],
      "metadata": {
        "id": "lAKYS95WLc_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fuentes\n",
        "Las fuentes consultadas en complemento con las clases de la materia serán añadidas en esta celda. A saber, se utilizaron como referencia:\n",
        "\n",
        "Video ilustrativo y muy útil para entender de que va la cosa: [1] https://www.youtube.com/watch?v=ZMudJXhsUpY&list=PLQY2H8rRoyvzDbLUZkbudP-MFQZwNmU4S&index=7\n",
        "\n",
        "\n",
        "Artículos de contexto para la temática de modelos de lenguaje: [2] https://developers.google.com/machine-learning/resources/intro-llms?hl=es-419#:~:text=A%20language%20model%20is%20a,a%20longer%20sequence%20of%20tokens.\n",
        "\n",
        "[3] https://builtin.com/data-science/beginners-guide-language-models\n",
        "\n",
        "Fuente proveída por la catedra para elegir una metrica para evaluar los modelos generativos: [4] https://towardsdatascience.com/how-to-evaluate-text-generation-models-metrics-for-automatic-evaluation-of-nlp-models-e1c251b04ec1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5kbBR8h1Lw7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jbbjx9lVSfWh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd19f91e-12cd-4e07-865a-2df1878d1fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Texto base\n",
        "El texto base elegido para entrenar los modelos es la novela corta de Franz Kafka, \"La Metamorfósis\"\n"
      ],
      "metadata": {
        "id": "Y8LYYT0ANfpy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "M8EkOJ1DrBTi",
        "outputId": "52abb5c1-a995-4cf7-a1d7-9ace7455f268"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'< eran las seis y media y las manecillas seguían tranquilamente hacia delante, ya había pasado incluso la media, eran ya casi las menos cuarto. «¿es que no habría sonado el despertador?» desde la cama se veía que estaba correctamente puesto a las cuatro, seguro que también había sonado. sí, pero... ¿era posible seguir durmiendo tan tranquilo con ese ruido que hacía temblar los muebles? bueno, tampoco había dormido tranquilo, pero quizá tanto más profundamente. >'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "#traemos la data, la segmentamos, separamos, preparamos\n",
        "#reverse_dictionary = token.index_word\n",
        "#dictionary = dict([(value, key) for (key, value) in reverse_dictionary.items()])\n",
        "TXTDIR= \"/content/drive/MyDrive/Colab Notebooks/La Metamorfosis.txt\"\n",
        "\n",
        "with open(TXTDIR, 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "parrafos = text.lower().split('\\n\\n') # Divido el contenido en parrafos y paso las letras a minúsculas.\n",
        "\n",
        "# Eliminamos enters y agregamos SOS y EOS\n",
        "dataset = [\"< \"+parrafo.strip().replace('\\n', ' ')+\" >\" for parrafo in parrafos if parrafo !=\"\"]\n",
        "dataset[11]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pequeño EDA.\n",
        "Como separamos el texto en parrafos que seran las entradas para el entrenamiento de los modelos, es util saber cuantos tenemos y que tan largos suelen ser los parrafos. Además es útil saber con cuantas palabras cuenta nuestra dataset."
      ],
      "metadata": {
        "id": "W3KZTOgh2cUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_size=len(dataset)\n",
        "print(\"Cantidad de parrafos: \",corpus_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P42_r_aPTwF5",
        "outputId": "552c9c06-9cc4-45af-ebdb-374e296433ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de parrafos:  193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "longitudes = [len(texto.split()) for texto in dataset]\n",
        "\n",
        "bin_edges = plt.hist(longitudes, bins=10, edgecolor='k', alpha=0.7)\n",
        "plt.xticks([50,120,200,300,400,800], ['50','120','200','300','400','800'])\n",
        "\n",
        "plt.title('Longitudes de Parrafos')\n",
        "plt.xlabel('Longitud')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "tbqLJvcNT-GR",
        "outputId": "26a2e55d-46bd-48f0-cc50-40e8c5f360b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenización"
      ],
      "metadata": {
        "id": "LZScOIcVjTVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Dividimos las oraciones en palabras\n",
        "words = [word for sentence in dataset for word in sentence.split()]\n",
        "#nos quedamos con las palabras unicas\n",
        "unique_words = set(words)\n",
        "\n",
        "num_words = len(unique_words)\n",
        "\n",
        "print(f\"Cantidad de palabras únicas: {num_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Yg7zkL7fFpm",
        "outputId": "d48a9712-b3c5-4be0-a0a1-9be8a3c7be45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de palabras únicas: 4660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import plot_model, to_categorical, pad_sequences\n",
        "\n",
        "token=Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n¡-¿»«—', lower=True, split=' ', char_level=False, oov_token=\"UNK\", document_count=0) #Instanciamos el tokenizador\n",
        "token.fit_on_texts(dataset)                                                                                                                                 # y fiteamos a nuestro dataset\n",
        "\n",
        "dictionary = token.index_word\n",
        "vocab_size=len(dictionary)+1\n",
        "print(\"Luego de removidos signos de puntuacion, la cantidad real de palabras a tokenizar es:\", vocab_size)"
      ],
      "metadata": {
        "id": "bkiAdo-weoKi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c184c835-2b21-463d-dd21-b74630764907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Luego de removidos signos de puntuacion, la cantidad real de palabras a tokenizar es: 3501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary"
      ],
      "metadata": {
        "id": "YewfGlebjHpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "458679d8-6293-4fa5-b89c-b740bbfc6e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'UNK',\n",
              " 2: 'la',\n",
              " 3: 'de',\n",
              " 4: 'que',\n",
              " 5: 'y',\n",
              " 6: 'el',\n",
              " 7: 'en',\n",
              " 8: 'a',\n",
              " 9: 'se',\n",
              " 10: 'con',\n",
              " 11: 'no',\n",
              " 12: 'su',\n",
              " 13: 'gregorio',\n",
              " 14: 'por',\n",
              " 15: 'un',\n",
              " 16: 'había',\n",
              " 17: 'los',\n",
              " 18: 'una',\n",
              " 19: 'las',\n",
              " 20: 'pero',\n",
              " 21: 'lo',\n",
              " 22: 'al',\n",
              " 23: 'ya',\n",
              " 24: 'del',\n",
              " 25: 'más',\n",
              " 26: 'para',\n",
              " 27: 'como',\n",
              " 28: 'le',\n",
              " 29: 'hermana',\n",
              " 30: 'habitación',\n",
              " 31: 'padre',\n",
              " 32: 'si',\n",
              " 33: 'todo',\n",
              " 34: 'madre',\n",
              " 35: 'sus',\n",
              " 36: 'estaba',\n",
              " 37: 'hacia',\n",
              " 38: 'puerta',\n",
              " 39: 'sin',\n",
              " 40: 'era',\n",
              " 41: 'tenía',\n",
              " 42: 'sobre',\n",
              " 43: 'porque',\n",
              " 44: 'cuando',\n",
              " 45: 'él',\n",
              " 46: 'podía',\n",
              " 47: 'ahora',\n",
              " 48: 'vez',\n",
              " 49: 'sólo',\n",
              " 50: 'es',\n",
              " 51: 'tiempo',\n",
              " 52: 'ella',\n",
              " 53: 'apoderado',\n",
              " 54: 'señor',\n",
              " 55: 'dijo',\n",
              " 56: 'otra',\n",
              " 57: 'hubiese',\n",
              " 58: 'después',\n",
              " 59: 'poco',\n",
              " 60: 'cabeza',\n",
              " 61: 'mismo',\n",
              " 62: 'desde',\n",
              " 63: 'esta',\n",
              " 64: 'habían',\n",
              " 65: 'muy',\n",
              " 66: 'momento',\n",
              " 67: 'samsa',\n",
              " 68: 'qué',\n",
              " 69: 'ni',\n",
              " 70: 'familia',\n",
              " 71: 'cama',\n",
              " 72: 'forma',\n",
              " 73: 'sí',\n",
              " 74: 'incluso',\n",
              " 75: 'así',\n",
              " 76: 'bien',\n",
              " 77: 'allí',\n",
              " 78: 'entonces',\n",
              " 79: 'este',\n",
              " 80: 'cómo',\n",
              " 81: 'hacía',\n",
              " 82: 'antes',\n",
              " 83: 'también',\n",
              " 84: 'mucho',\n",
              " 85: 'parte',\n",
              " 86: 'todavía',\n",
              " 87: 'casa',\n",
              " 88: 'pesar',\n",
              " 89: 'padres',\n",
              " 90: 'casi',\n",
              " 91: 'quizá',\n",
              " 92: 'sido',\n",
              " 93: 'suelo',\n",
              " 94: 'e',\n",
              " 95: 'durante',\n",
              " 96: 'mientras',\n",
              " 97: 'voz',\n",
              " 98: 'me',\n",
              " 99: 'todas',\n",
              " 100: 'veces',\n",
              " 101: 'gran',\n",
              " 102: 'ello',\n",
              " 103: 'nada',\n",
              " 104: 'dos',\n",
              " 105: 'usted',\n",
              " 106: 'esto',\n",
              " 107: 'estar',\n",
              " 108: 'todos',\n",
              " 109: 'greta',\n",
              " 110: 'o',\n",
              " 111: 'lado',\n",
              " 112: 'estado',\n",
              " 113: 'ser',\n",
              " 114: 'parecía',\n",
              " 115: 'mañana',\n",
              " 116: 'entre',\n",
              " 117: 'mesa',\n",
              " 118: 'ver',\n",
              " 119: 'inmediatamente',\n",
              " 120: 'toda',\n",
              " 121: 'hacer',\n",
              " 122: 'ojos',\n",
              " 123: 'nuevo',\n",
              " 124: 'cuarto',\n",
              " 125: 'quería',\n",
              " 126: 'hasta',\n",
              " 127: 'asistenta',\n",
              " 128: 'ante',\n",
              " 129: 'algo',\n",
              " 130: 'otro',\n",
              " 131: 'contra',\n",
              " 132: 'solamente',\n",
              " 133: 'siempre',\n",
              " 134: 'canapé',\n",
              " 135: 'tanto',\n",
              " 136: 'alguna',\n",
              " 137: 'manos',\n",
              " 138: 'cuerpo',\n",
              " 139: 'vuelta',\n",
              " 140: 'silla',\n",
              " 141: 'sino',\n",
              " 142: 'ha',\n",
              " 143: 'permanecía',\n",
              " 144: 'ese',\n",
              " 145: 'tan',\n",
              " 146: 'menos',\n",
              " 147: 'daba',\n",
              " 148: 'lugar',\n",
              " 149: 'silencio',\n",
              " 150: 'estaban',\n",
              " 151: 'espalda',\n",
              " 152: 'apenas',\n",
              " 153: 'ventana',\n",
              " 154: 'fuerza',\n",
              " 155: 'pronto',\n",
              " 156: 'trabajo',\n",
              " 157: 'cuenta',\n",
              " 158: 'atención',\n",
              " 159: 'dio',\n",
              " 160: 'nadie',\n",
              " 161: 'mano',\n",
              " 162: 'huéspedes',\n",
              " 163: 'día',\n",
              " 164: 'posible',\n",
              " 165: 'principio',\n",
              " 166: 'cierto',\n",
              " 167: 'ellos',\n",
              " 168: 'tres',\n",
              " 169: 'entrar',\n",
              " 170: 'hecho',\n",
              " 171: 'alrededor',\n",
              " 172: 'completamente',\n",
              " 173: 'mujeres',\n",
              " 174: 'veía',\n",
              " 175: 'encontraba',\n",
              " 176: 'además',\n",
              " 177: 'mejor',\n",
              " 178: 'delante',\n",
              " 179: 'muebles',\n",
              " 180: 'haber',\n",
              " 181: 'tarde',\n",
              " 182: 'unos',\n",
              " 183: 'uno',\n",
              " 184: 'jefe',\n",
              " 185: 'dinero',\n",
              " 186: 'tampoco',\n",
              " 187: 'seguramente',\n",
              " 188: 'realmente',\n",
              " 189: 'palabras',\n",
              " 190: 'tal',\n",
              " 191: 'patitas',\n",
              " 192: 'cuidado',\n",
              " 193: 'modo',\n",
              " 194: 'debía',\n",
              " 195: 'par',\n",
              " 196: 'medio',\n",
              " 197: 'naturalmente',\n",
              " 198: 'noche',\n",
              " 199: 'cosas',\n",
              " 200: 'cual',\n",
              " 201: 'nunca',\n",
              " 202: 'comida',\n",
              " 203: 'armario',\n",
              " 204: 'eran',\n",
              " 205: 'estas',\n",
              " 206: 'gritó',\n",
              " 207: 'intención',\n",
              " 208: 'aún',\n",
              " 209: 'aquí',\n",
              " 210: 'embargo',\n",
              " 211: 'llave',\n",
              " 212: 'tumbado',\n",
              " 213: 'pequeña',\n",
              " 214: 'almacén',\n",
              " 215: 'otros',\n",
              " 216: 'yo',\n",
              " 217: 'podría',\n",
              " 218: 'demás',\n",
              " 219: 'habría',\n",
              " 220: 'bueno',\n",
              " 221: 'miró',\n",
              " 222: 'ruido',\n",
              " 223: 'iba',\n",
              " 224: 'primer',\n",
              " 225: 'decir',\n",
              " 226: 'fuera',\n",
              " 227: 'fin',\n",
              " 228: 'pues',\n",
              " 229: 'debajo',\n",
              " 230: 'fue',\n",
              " 231: 'vida',\n",
              " 232: 'podido',\n",
              " 233: 'cada',\n",
              " 234: 'siquiera',\n",
              " 235: 'arrastrarse',\n",
              " 236: 'les',\n",
              " 237: 'violín',\n",
              " 238: 'lentamente',\n",
              " 239: 'sabía',\n",
              " 240: 'eso',\n",
              " 241: 'mi',\n",
              " 242: 'está',\n",
              " 243: 'abrir',\n",
              " 244: 'brazos',\n",
              " 245: 'movimiento',\n",
              " 246: 'hizo',\n",
              " 247: 'abierta',\n",
              " 248: 'vestíbulo',\n",
              " 249: 'detrás',\n",
              " 250: 'sitio',\n",
              " 251: 'tener',\n",
              " 252: 'esa',\n",
              " 253: 'suficiente',\n",
              " 254: 'años',\n",
              " 255: 'dado',\n",
              " 256: 'comenzó',\n",
              " 257: 'verdad',\n",
              " 258: 'quedó',\n",
              " 259: 'abrió',\n",
              " 260: 'horas',\n",
              " 261: 'necesario',\n",
              " 262: 'días',\n",
              " 263: 'señora',\n",
              " 264: 'tiempos',\n",
              " 265: 'duda',\n",
              " 266: 'boca',\n",
              " 267: 'contrario',\n",
              " 268: 'demasiado',\n",
              " 269: 'junto',\n",
              " 270: 'sentía',\n",
              " 271: 'pensó',\n",
              " 272: 'encima',\n",
              " 273: 'mucha',\n",
              " 274: 'poder',\n",
              " 275: 'sería',\n",
              " 276: 'cinco',\n",
              " 277: 'seguro',\n",
              " 278: 'caso',\n",
              " 279: 'probablemente',\n",
              " 280: 'tras',\n",
              " 281: 'cerrar',\n",
              " 282: 'pensar',\n",
              " 283: 'cosa',\n",
              " 284: 'decía',\n",
              " 285: 'desgracia',\n",
              " 286: 'pensaba',\n",
              " 287: 'escuchar',\n",
              " 288: 'quien',\n",
              " 289: 'consecuencia',\n",
              " 290: 'derecha',\n",
              " 291: 'enseguida',\n",
              " 292: 'consideración',\n",
              " 293: 'puede',\n",
              " 294: 'bajo',\n",
              " 295: 'continuación',\n",
              " 296: 'pie',\n",
              " 297: 'rostro',\n",
              " 298: 'partes',\n",
              " 299: 'paredes',\n",
              " 300: 'levantaba',\n",
              " 301: 'caer',\n",
              " 302: 'dios',\n",
              " 303: 'viaje',\n",
              " 304: 'tren',\n",
              " 305: 'señores',\n",
              " 306: 'tengo',\n",
              " 307: 'puesto',\n",
              " 308: 'tranquilo',\n",
              " 309: 'siete',\n",
              " 310: 'especialmente',\n",
              " 311: 'hambre',\n",
              " 312: 'dejaba',\n",
              " 313: 'oído',\n",
              " 314: 'volvió',\n",
              " 315: 'difícil',\n",
              " 316: 'ellas',\n",
              " 317: 'permanecer',\n",
              " 318: 'aire',\n",
              " 319: 'herida',\n",
              " 320: 'permaneció',\n",
              " 321: 'ayuda',\n",
              " 322: 'dentro',\n",
              " 323: 'mayor',\n",
              " 324: 'nosotros',\n",
              " 325: 'últimos',\n",
              " 326: 'cocina',\n",
              " 327: 'misma',\n",
              " 328: 'donde',\n",
              " 329: 'levantó',\n",
              " 330: 'comer',\n",
              " 331: 'sueño',\n",
              " 332: 'punto',\n",
              " 333: 'muchas',\n",
              " 334: 'colocado',\n",
              " 335: 'mirada',\n",
              " 336: 'actual',\n",
              " 337: 'aunque',\n",
              " 338: 'hombre',\n",
              " 339: 'estos',\n",
              " 340: 'desayuno',\n",
              " 341: 'calle',\n",
              " 342: 'dicho',\n",
              " 343: 'llegado',\n",
              " 344: 'profundamente',\n",
              " 345: 'sola',\n",
              " 346: 'cambio',\n",
              " 347: 'gracias',\n",
              " 348: 'puertas',\n",
              " 349: 'estoy',\n",
              " 350: 'pudiese',\n",
              " 351: 'varias',\n",
              " 352: 'absoluto',\n",
              " 353: 'dirección',\n",
              " 354: 'precisamente',\n",
              " 355: 'quedarse',\n",
              " 356: 'tomar',\n",
              " 357: 'tales',\n",
              " 358: 'criada',\n",
              " 359: 'necesidad',\n",
              " 360: 'contigua',\n",
              " 361: 'palabra',\n",
              " 362: 'preguntó',\n",
              " 363: 'dar',\n",
              " 364: 'motivo',\n",
              " 365: 'ustedes',\n",
              " 366: 'nos',\n",
              " 367: 'tuvo',\n",
              " 368: 'ésta',\n",
              " 369: 'darse',\n",
              " 370: 'cayó',\n",
              " 371: 'cerró',\n",
              " 372: 'especial',\n",
              " 373: 'dejar',\n",
              " 374: 'alegría',\n",
              " 375: 'completo',\n",
              " 376: 'rápidamente',\n",
              " 377: 'viejo',\n",
              " 378: 'abría',\n",
              " 379: 'música',\n",
              " 380: 'inmóvil',\n",
              " 381: 'sábana',\n",
              " 382: 'cuadro',\n",
              " 383: 'acostumbrado',\n",
              " 384: 'volvía',\n",
              " 385: 'dolor',\n",
              " 386: 'he',\n",
              " 387: 'constantemente',\n",
              " 388: 'totalmente',\n",
              " 389: 'posición',\n",
              " 390: 'levantarse',\n",
              " 391: 'hace',\n",
              " 392: 'tiene',\n",
              " 393: 'largo',\n",
              " 394: 'mis',\n",
              " 395: 'opinión',\n",
              " 396: 'hablar',\n",
              " 397: 'tranquilamente',\n",
              " 398: 'tendría',\n",
              " 399: 'evitar',\n",
              " 400: 'médico',\n",
              " 401: 'razón',\n",
              " 402: 'abandonar',\n",
              " 403: 'salir',\n",
              " 404: 'circunstancias',\n",
              " 405: 'conversación',\n",
              " 406: 'algún',\n",
              " 407: 'mal',\n",
              " 408: 'hubiera',\n",
              " 409: 'primera',\n",
              " 410: 'finalmente',\n",
              " 411: 'momentos',\n",
              " 412: 'entró',\n",
              " 413: 'posibilidad',\n",
              " 414: 'orden',\n",
              " 415: 'podían',\n",
              " 416: 'alfombra',\n",
              " 417: 'pensamientos',\n",
              " 418: 'periódico',\n",
              " 419: 'acababa',\n",
              " 420: 'yacía',\n",
              " 421: 'tenido',\n",
              " 422: 'exclamó',\n",
              " 423: 'cierta',\n",
              " 424: 'tranquilidad',\n",
              " 425: 'dejó',\n",
              " 426: 'través',\n",
              " 427: 'dejado',\n",
              " 428: 'fueron',\n",
              " 429: 'luego',\n",
              " 430: 'efectivamente',\n",
              " 431: 'llevar',\n",
              " 432: 'quisiera',\n",
              " 433: 'cerrada',\n",
              " 434: 'uniforme',\n",
              " 435: 'escalera',\n",
              " 436: 'vista',\n",
              " 437: 'corría',\n",
              " 438: 'bastón',\n",
              " 439: 'fuese',\n",
              " 440: 'situación',\n",
              " 441: 'larga',\n",
              " 442: 'algunas',\n",
              " 443: 'lágrimas',\n",
              " 444: 'señal',\n",
              " 445: 'escuchaba',\n",
              " 446: 'pasaba',\n",
              " 447: 'aspecto',\n",
              " 448: 'éste',\n",
              " 449: 'manzana',\n",
              " 450: 'levantar',\n",
              " 451: 'vientre',\n",
              " 452: 'resto',\n",
              " 453: 'ocurrido',\n",
              " 454: 'aquel',\n",
              " 455: 'ponía',\n",
              " 456: 'derecho',\n",
              " 457: 'intentó',\n",
              " 458: 'costado',\n",
              " 459: 'sentido',\n",
              " 460: 'mío',\n",
              " 461: 'sintió',\n",
              " 462: 'cerca',\n",
              " 463: 'debían',\n",
              " 464: 'producía',\n",
              " 465: 'conseguido',\n",
              " 466: 'abajo',\n",
              " 467: 'culpa',\n",
              " 468: 'seguridad',\n",
              " 469: 'seguían',\n",
              " 470: 'seguir',\n",
              " 471: 'salía',\n",
              " 472: 'prisa',\n",
              " 473: 'enfermo',\n",
              " 474: 'bastante',\n",
              " 475: 'asustó',\n",
              " 476: 'sonido',\n",
              " 477: 'hoy',\n",
              " 478: 'necesitaba',\n",
              " 479: 'solo',\n",
              " 480: 'inútilmente',\n",
              " 481: 'sacar',\n",
              " 482: 'lentitud',\n",
              " 483: 'miedo',\n",
              " 484: 'continuar',\n",
              " 485: 'ningún',\n",
              " 486: 'esfuerzo',\n",
              " 487: 'fuerte',\n",
              " 488: 'ocurrió',\n",
              " 489: 'pudo',\n",
              " 490: 'paso',\n",
              " 491: 'hablaba',\n",
              " 492: 'sentado',\n",
              " 493: 'pequeño',\n",
              " 494: 'vamos',\n",
              " 495: 'quiere',\n",
              " 496: 'año',\n",
              " 497: 'grandes',\n",
              " 498: 'intentaba',\n",
              " 499: 'ir',\n",
              " 500: 'primeras',\n",
              " 501: 'fuerzas',\n",
              " 502: 'mantenía',\n",
              " 503: 'hoja',\n",
              " 504: 'vio',\n",
              " 505: 'miraba',\n",
              " 506: 'trabajar',\n",
              " 507: 'terminado',\n",
              " 508: 'última',\n",
              " 509: 'tenían',\n",
              " 510: 'abierto',\n",
              " 511: 'olvidado',\n",
              " 512: 'atrás',\n",
              " 513: 'voluntad',\n",
              " 514: 'empujaba',\n",
              " 515: 'aun',\n",
              " 516: 'leche',\n",
              " 517: 'solía',\n",
              " 518: 'oscuridad',\n",
              " 519: 'trataba',\n",
              " 520: 'gusto',\n",
              " 521: 'trozo',\n",
              " 522: 'escoba',\n",
              " 523: 'frecuencia',\n",
              " 524: 'quedaba',\n",
              " 525: 'ciertamente',\n",
              " 526: 'escritorio',\n",
              " 527: 'camino',\n",
              " 528: 'brazo',\n",
              " 529: 'corrió',\n",
              " 530: 'cuello',\n",
              " 531: 'amigos',\n",
              " 532: 'hija',\n",
              " 533: 'despertó',\n",
              " 534: 'encontró',\n",
              " 535: 'convertido',\n",
              " 536: 'cuya',\n",
              " 537: 'patas',\n",
              " 538: 'cuatro',\n",
              " 539: 'viajante',\n",
              " 540: 'pesado',\n",
              " 541: 'dirigió',\n",
              " 542: 'imposible',\n",
              " 543: 'dormir',\n",
              " 544: 'ciudad',\n",
              " 545: 'deslizó',\n",
              " 546: 'retiró',\n",
              " 547: 'sentados',\n",
              " 548: 'intentar',\n",
              " 549: 'quién',\n",
              " 550: 'caído',\n",
              " 551: 'costumbre',\n",
              " 552: 'esperanza',\n",
              " 553: 'despertador',\n",
              " 554: 'media',\n",
              " 555: 'pasado',\n",
              " 556: 'dormido',\n",
              " 557: 'servicio',\n",
              " 558: 'instante',\n",
              " 559: 'causa',\n",
              " 560: 'grave',\n",
              " 561: 'baja',\n",
              " 562: 'contestó',\n",
              " 563: 'grande',\n",
              " 564: 'hay',\n",
              " 565: 'despacio',\n",
              " 566: 'siguió',\n",
              " 567: 'perder',\n",
              " 568: 'semejante',\n",
              " 569: 'poner',\n",
              " 570: 'espectáculo',\n",
              " 571: 'sonó',\n",
              " 572: 'esperase',\n",
              " 573: 'alguien',\n",
              " 574: 'caída',\n",
              " 575: 'preocupación',\n",
              " 576: 'deprisa',\n",
              " 577: 'persona',\n",
              " 578: 'simplemente',\n",
              " 579: 'venir',\n",
              " 580: 'rabia',\n",
              " 581: 'izquierda',\n",
              " 582: 'pasos',\n",
              " 583: 'adentros',\n",
              " 584: 'alto',\n",
              " 585: 'pudiera',\n",
              " 586: 'saber',\n",
              " 587: 'favor',\n",
              " 588: 'amablemente',\n",
              " 589: 'cuanto',\n",
              " 590: 'según',\n",
              " 591: 'negocios',\n",
              " 592: 'seriamente',\n",
              " 593: 'comportamiento',\n",
              " 594: 'falta',\n",
              " 595: 'obstinación',\n",
              " 596: 'creía',\n",
              " 597: 'alguno',\n",
              " 598: 'enmudeció',\n",
              " 599: 'buscar',\n",
              " 600: 'dando',\n",
              " 601: 'cerrajero',\n",
              " 602: 'vestido',\n",
              " 603: 'suficientemente',\n",
              " 604: 'respecto',\n",
              " 605: 'conversaciones',\n",
              " 606: 'cerradura',\n",
              " 607: 'dientes',\n",
              " 608: 'idea',\n",
              " 609: 'capaz',\n",
              " 610: 'alta',\n",
              " 611: 'arriba',\n",
              " 612: 'inclinada',\n",
              " 613: 'enfrente',\n",
              " 614: 'caía',\n",
              " 615: 'pared',\n",
              " 616: 'realidad',\n",
              " 617: 'visión',\n",
              " 618: 'fácilmente',\n",
              " 619: 'mayoría',\n",
              " 620: 'carne',\n",
              " 621: 'creído',\n",
              " 622: 'perdido',\n",
              " 623: 'abandonó',\n",
              " 624: 'barandilla',\n",
              " 625: 'advirtió',\n",
              " 626: 'retrocedió',\n",
              " 627: 'pareció',\n",
              " 628: 'mirando',\n",
              " 629: 'perdía',\n",
              " 630: 'techo',\n",
              " 631: 'escudilla',\n",
              " 632: 'pan',\n",
              " 633: 'resultaba',\n",
              " 634: 'oía',\n",
              " 635: 'vacía',\n",
              " 636: 'ocasión',\n",
              " 637: 'decidido',\n",
              " 638: 'temprano',\n",
              " 639: 'querían',\n",
              " 640: 'comprobar',\n",
              " 641: 'oportunidad',\n",
              " 642: 'prueba',\n",
              " 643: 'cena',\n",
              " 644: 'echó',\n",
              " 645: 'ninguna',\n",
              " 646: 'comía',\n",
              " 647: 'explicaciones',\n",
              " 648: 'ganar',\n",
              " 649: 'puro',\n",
              " 650: 'golpeaba',\n",
              " 651: 'tocar',\n",
              " 652: 'dormía',\n",
              " 653: 'recuerdo',\n",
              " 654: 'entrase',\n",
              " 655: 'impedía',\n",
              " 656: 'nueva',\n",
              " 657: 'chica',\n",
              " 658: 'direcciones',\n",
              " 659: 'primero',\n",
              " 660: 'llevaba',\n",
              " 661: 'sentir',\n",
              " 662: 'frente',\n",
              " 663: 'miradas',\n",
              " 664: 'preocuparse',\n",
              " 665: 'bolsillos',\n",
              " 666: 'empezó',\n",
              " 667: 'tienda',\n",
              " 668: 'polvo',\n",
              " 669: 'rincón',\n",
              " 670: 'dormitorio',\n",
              " 671: 'casualidad',\n",
              " 672: 'permanecieron',\n",
              " 673: 'cadáver',\n",
              " 674: 'arco',\n",
              " 675: 'pequeñas',\n",
              " 676: 'auténtica',\n",
              " 677: 'humana',\n",
              " 678: 'muestrario',\n",
              " 679: 'comercio',\n",
              " 680: 'colgado',\n",
              " 681: 'sombrero',\n",
              " 682: 'sentada',\n",
              " 683: 'lluvia',\n",
              " 684: 'pasaría',\n",
              " 685: 'ponerse',\n",
              " 686: 'comenzaba',\n",
              " 687: 'leve',\n",
              " 688: 'esfuerzos',\n",
              " 689: 'viajar',\n",
              " 690: 'pequeños',\n",
              " 691: 'pata',\n",
              " 692: 'ejemplo',\n",
              " 693: 'pasar',\n",
              " 694: 'sabe',\n",
              " 695: 'mí',\n",
              " 696: 'extraña',\n",
              " 697: 'sentarse',\n",
              " 698: 'altura',\n",
              " 699: 'empleado',\n",
              " 700: 'puedo',\n",
              " 701: 'seis',\n",
              " 702: 'haberse',\n",
              " 703: 'esperado',\n",
              " 704: 'descuido',\n",
              " 705: 'haría',\n",
              " 706: 'reproches',\n",
              " 707: 'excepción',\n",
              " 708: 'rapidez',\n",
              " 709: 'escuchó',\n",
              " 710: 'profundo',\n",
              " 711: 'notaba',\n",
              " 712: 'respuesta',\n",
              " 713: 'breve',\n",
              " 714: 'llamaba',\n",
              " 715: 'puño',\n",
              " 716: 'ambos',\n",
              " 717: 'preparado',\n",
              " 718: 'abre',\n",
              " 719: 'menor',\n",
              " 720: 'vestirse',\n",
              " 721: 'conclusión',\n",
              " 722: 'producido',\n",
              " 723: 'resultado',\n",
              " 724: 'curiosidad',\n",
              " 725: 'buen',\n",
              " 726: 'ancho',\n",
              " 727: 'movimientos',\n",
              " 728: 'estiraba',\n",
              " 729: 'inferior',\n",
              " 730: 'lanzó',\n",
              " 731: 'fuertemente',\n",
              " 732: 'facilidad',\n",
              " 733: 'peso',\n",
              " 734: 'giro',\n",
              " 735: 'ocurrir',\n",
              " 736: 'sensato',\n",
              " 737: 'dirigía',\n",
              " 738: 'ánimo',\n",
              " 739: 'respirando',\n",
              " 740: 'salido',\n",
              " 741: 'sea',\n",
              " 742: 'venido',\n",
              " 743: 'pretendía',\n",
              " 744: 'posiblemente',\n",
              " 745: 'sobresalía',\n",
              " 746: 'fácil',\n",
              " 747: 'hubiesen',\n",
              " 748: 'firme',\n",
              " 749: 'servicios',\n",
              " 750: 'mínimo',\n",
              " 751: 'estuviese',\n",
              " 752: 'asunto',\n",
              " 753: 'irritación',\n",
              " 754: 'decisión',\n",
              " 755: 'produjo',\n",
              " 756: 'golpe',\n",
              " 757: 'auténtico',\n",
              " 758: 'pensado',\n",
              " 759: 'debió',\n",
              " 760: 'ahí',\n",
              " 761: 'parecido',\n",
              " 762: 'ocurría',\n",
              " 763: 'haberlo',\n",
              " 764: 'bondad',\n",
              " 765: 'buenos',\n",
              " 766: 'encuentra',\n",
              " 767: 'negocio',\n",
              " 768: 'ocho',\n",
              " 769: 'pasó',\n",
              " 770: 'tardes',\n",
              " 771: 'solos',\n",
              " 772: 'suerte',\n",
              " 773: 'tenemos',\n",
              " 774: 'empezado',\n",
              " 775: 'éstas',\n",
              " 776: 'preocupaciones',\n",
              " 777: 'dejase',\n",
              " 778: 'levantando',\n",
              " 779: 'explicación',\n",
              " 780: 'clara',\n",
              " 781: 'inmediata',\n",
              " 782: 'repente',\n",
              " 783: 'empezar',\n",
              " 784: 'veo',\n",
              " 785: 'cara',\n",
              " 786: 'época',\n",
              " 787: 'han',\n",
              " 788: 'apoyado',\n",
              " 789: 'deseaba',\n",
              " 790: 'presencia',\n",
              " 791: 'dolores',\n",
              " 792: 'cuyos',\n",
              " 793: 'agarró',\n",
              " 794: 'amor',\n",
              " 795: 'tienes',\n",
              " 796: 'oír',\n",
              " 797: 'tono',\n",
              " 798: 'gritos',\n",
              " 799: 've',\n",
              " 800: 'oyó',\n",
              " 801: 'humano',\n",
              " 802: 'esperaba',\n",
              " 803: 'hacerlo',\n",
              " 804: 'distinta',\n",
              " 805: 'reinaba',\n",
              " 806: 'acercó',\n",
              " 807: 'arrojó',\n",
              " 808: 'mandíbulas',\n",
              " 809: 'apretaba',\n",
              " 810: 'apoyó',\n",
              " 811: 'pecho',\n",
              " 812: 'extendidas',\n",
              " 813: 'justamente',\n",
              " 814: 'rellano',\n",
              " 815: 'vivir',\n",
              " 816: 'superado',\n",
              " 817: 'obstáculo',\n",
              " 818: 'conjunto',\n",
              " 819: 'confianza',\n",
              " 820: 'propia',\n",
              " 821: 'estuvo',\n",
              " 822: 'repentino',\n",
              " 823: 'sacó',\n",
              " 824: 'lejos',\n",
              " 825: 'previsión',\n",
              " 826: 'atraído',\n",
              " 827: 'futuro',\n",
              " 828: 'ambas',\n",
              " 829: 'hubo',\n",
              " 830: 'verlo',\n",
              " 831: 'adivinar',\n",
              " 832: 'relativamente',\n",
              " 833: 'retroceder',\n",
              " 834: 'mantener',\n",
              " 835: 'buena',\n",
              " 836: 'feliz',\n",
              " 837: 'consistía',\n",
              " 838: 'moverse',\n",
              " 839: 'llena',\n",
              " 840: 'llorar',\n",
              " 841: 'traído',\n",
              " 842: 'gustaba',\n",
              " 843: 'repugnancia',\n",
              " 844: 'rendija',\n",
              " 845: 'fijamente',\n",
              " 846: 'proporcionar',\n",
              " 847: 'llevaban',\n",
              " 848: 'satisfacción',\n",
              " 849: 'final',\n",
              " 850: 'manera',\n",
              " 851: 'luz',\n",
              " 852: 'permanecido',\n",
              " 853: 'puntillas',\n",
              " 854: 'molestase',\n",
              " 855: 'impresión',\n",
              " 856: 'inconsciente',\n",
              " 857: 'vergüenza',\n",
              " 858: 'cómodo',\n",
              " 859: 'extraño',\n",
              " 860: 'traería',\n",
              " 861: 'pies',\n",
              " 862: 'cuyo',\n",
              " 863: 'queso',\n",
              " 864: 'asombró',\n",
              " 865: 'mes',\n",
              " 866: 'soportar',\n",
              " 867: 'retirarse',\n",
              " 868: 'utilizar',\n",
              " 869: 'cubo',\n",
              " 870: 'recibía',\n",
              " 871: 'mediodía',\n",
              " 872: 'comido',\n",
              " 873: 'tristeza',\n",
              " 874: 'habitaciones',\n",
              " 875: 'comidas',\n",
              " 876: 'pedido',\n",
              " 877: 'hora',\n",
              " 878: 'desesperación',\n",
              " 879: 'otras',\n",
              " 880: 'conservatorio',\n",
              " 881: 'decididamente',\n",
              " 882: 'dirigiéndose',\n",
              " 883: 'luces',\n",
              " 884: 'meses',\n",
              " 885: 'pocos',\n",
              " 886: 'ayudar',\n",
              " 887: 'empezaba',\n",
              " 888: 'anteriormente',\n",
              " 889: 'atenta',\n",
              " 890: 'darle',\n",
              " 891: 'hiciese',\n",
              " 892: 'llegó',\n",
              " 893: 'esperar',\n",
              " 894: 'corriendo',\n",
              " 895: 'detalle',\n",
              " 896: 'mejoría',\n",
              " 897: 'comprendía',\n",
              " 898: 'impedían',\n",
              " 899: 'colocar',\n",
              " 900: 'temía',\n",
              " 901: 'abandonado',\n",
              " 902: 'creo',\n",
              " 903: 'asuntos',\n",
              " 904: 'pura',\n",
              " 905: 'cartas',\n",
              " 906: 'sujetaba',\n",
              " 907: 'acostumbrada',\n",
              " 908: 'moviese',\n",
              " 909: 'detuvo',\n",
              " 910: 'confesarse',\n",
              " 911: 'mujer',\n",
              " 912: 'apresuradamente',\n",
              " 913: 'cristal',\n",
              " 914: 'ven',\n",
              " 915: 'rompió',\n",
              " 916: 'echar',\n",
              " 917: 'precipitó',\n",
              " 918: 'botones',\n",
              " 919: 'gorra',\n",
              " 920: 'abiertos',\n",
              " 921: 'correr',\n",
              " 922: 'susto',\n",
              " 923: 'general',\n",
              " 924: 'ropa',\n",
              " 925: 'conseguir',\n",
              " 926: 'efecto',\n",
              " 927: 'hombros',\n",
              " 928: 'gente',\n",
              " 929: 'daban',\n",
              " 930: 'noches',\n",
              " 931: 'llegar',\n",
              " 932: 'suciedad',\n",
              " 933: 'fuente',\n",
              " 934: 'levantaban',\n",
              " 935: 'levantaron',\n",
              " 936: 'partitura',\n",
              " 937: 'bestia',\n",
              " 938: 'huésped',\n",
              " 939: 'digo',\n",
              " 940: 'dura',\n",
              " 941: 'caparazón',\n",
              " 942: 'parduzco',\n",
              " 943: 'cobertor',\n",
              " 944: 'tamaño',\n",
              " 945: 'tranquila',\n",
              " 946: 'extendido',\n",
              " 947: 'bonito',\n",
              " 948: 'marco',\n",
              " 949: 'dorado',\n",
              " 950: 'representaba',\n",
              " 951: 'piel',\n",
              " 952: 'oían',\n",
              " 953: 'gotas',\n",
              " 954: 'olvidase',\n",
              " 955: 'absolutamente',\n",
              " 956: 'balancear',\n",
              " 957: 'empeño',\n",
              " 958: 'notar',\n",
              " 959: 'sordo',\n",
              " 960: 'profesionales',\n",
              " 961: 'son',\n",
              " 962: 'jamás',\n",
              " 963: 'llega',\n",
              " 964: 'cabecera',\n",
              " 965: 'quiso',\n",
              " 966: 'viajantes',\n",
              " 967: 'pedidos',\n",
              " 968: 'despedido',\n",
              " 969: 'acercarse',\n",
              " 970: 'deudas',\n",
              " 971: 'tienen',\n",
              " 972: 'habrá',\n",
              " 973: 'levantarme',\n",
              " 974: 'cielo',\n",
              " 975: 'sonado',\n",
              " 976: 'siguiente',\n",
              " 977: 'mozo',\n",
              " 978: 'recados',\n",
              " 979: 'juicio',\n",
              " 980: 'dijese',\n",
              " 981: 'sumamente',\n",
              " 982: 'desagradable',\n",
              " 983: 'sospechoso',\n",
              " 984: 'hijo',\n",
              " 985: 'dulce',\n",
              " 986: 'evidentemente',\n",
              " 987: 'suya',\n",
              " 988: 'claridad',\n",
              " 989: 'levanto',\n",
              " 990: 'madera',\n",
              " 991: 'miembros',\n",
              " 992: 'suavemente',\n",
              " 993: 'ocurre',\n",
              " 994: 'instantes',\n",
              " 995: 'lateral',\n",
              " 996: 'te',\n",
              " 997: 'haciendo',\n",
              " 998: 'llamar',\n",
              " 999: 'susurró',\n",
              " 1000: 'precaución',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Genero secuencias para el entrenamiento. Para ello tomo oraciones, las tokenizo, y armo dos listas, una que contenga una oracion menos su ultima palabra y la otra con la palabra que iría a continuación. Esto es similar al caso de tener data con sus respectivos labels. A la vez aprovecho y padeo las secuencias para que tengan el mismo tamaño, y las palabras de salida o labels paso a representarlos como una categoría (one-hot encoding). Con esta idea notamos que para los modelos que se entrenan aqui la dimension de entrada es fija."
      ],
      "metadata": {
        "id": "VvNAMjMukMR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_seqs = token.texts_to_sequences(dataset)  # Tokenizo los textos\n",
        "max_len=500                                         #Del EDA notamos que los parrafos son de hasta 500 palabras en su gran mayoría, por eso tomamos de tamaño maximo de largo de contexto 500.\n",
        "x_sequences = []\n",
        "y_sequences = []\n",
        "for text in tokenized_seqs:\n",
        "  for i in range(1,len(text)):\n",
        "      x_sequences.append(text[:i])  # Arreglos de entrada\n",
        "      y_sequences.append(text[i])   # Arreglos de salida\n",
        "x_sequences = pad_sequences(x_sequences, maxlen=max_len, padding='pre', truncating='pre')\n",
        "y_sequences = to_categorical(y_sequences, num_classes=len(token.index_word)+1)              #Al usar one-hot, usaremos como loss Categorical-Cross\n",
        "\n"
      ],
      "metadata": {
        "id": "-xqeKZBZknLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_sequences.shape)\n",
        "print(y_sequences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IfwMSXv3cEB",
        "outputId": "19c606a5-4b9b-406c-8dff-9f722bbcfdd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20612, 500)\n",
            "(20612, 3501)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizemos una\n",
        "print(\"Para la oracion:\")\n",
        "print(token.sequences_to_texts([x_sequences[13][-6:]])[0])\n",
        "print(\"La siguiente palabra sería:\")\n",
        "print(token.index_word[(np.argmax(y_sequences[13]))])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfQDVvMfm7Gt",
        "outputId": "e281d92e-4da6-46c6-f148-6111de547320"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Para la oracion:\n",
            "después de un sueño intranquilo se\n",
            "La siguiente palabra sería:\n",
            "encontró\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargamos embeddings pre entrenados\n",
        "Cargamos los embeddings que provee fasttext para el idioma español"
      ],
      "metadata": {
        "id": "5ksUdBt0npOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import codecs\n",
        "#load embeddings\n",
        "EMBEDDING_DIR = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "print('loading word embeddings...')\n",
        "embeddings_index = {}\n",
        "f = codecs.open(EMBEDDING_DIR+'cc.es.300.vec', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('found %s word vectors' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45K4SMsVjb8t",
        "outputId": "4950117e-d6fa-4619-a217-cd882e768d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n",
            "found 2000000 word vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teniendo los embeddings para las 2M de palabras, ahora procedemos a armar nuestra matriz de embeddings, es decir, nos quedamos con las palabras que figuran en nuestro texto y les damos sus significados semánticos extraidos segun fastText.\n",
        "\n",
        "Mas info sobre estos en: https://fasttext.cc/docs/en/crawl-vectors.html"
      ],
      "metadata": {
        "id": "cqljZcea3b_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 300\n",
        "embedding_matrix = np.zeros([vocab_size, embed_dim])\n",
        "for idx, word in dictionary.items():\n",
        "    if idx < vocab_size and word in embeddings_index:\n",
        "        embedding_matrix[idx,:] = embeddings_index[word]"
      ],
      "metadata": {
        "id": "Lte09MKT2NJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Métricas\n",
        "En cuanto a las metricas de evaluación mas relevantes para el analisis de performance se consideraron las mencionadas en la fuente referenciada mas arriba, a saber:\n",
        "\n",
        "Consultando con otros grupos se decidió utilizar la metrica de perplejidad, la cual conceptualmente tiene mucho sentido ya que plantea alimentar al modelo con oraciones reales propias del set de datos y promediar las probabilidades de que acierte correctamente la \"respuesta correcta\", en este caso la siguiente palabra"
      ],
      "metadata": {
        "id": "sTKQO7iP9uql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Perplexity(text_set, tokenizer, model, max_len=500):\n",
        "  perp = np.array([])\n",
        "  x_sequ = []\n",
        "  y_sequ = []\n",
        "\n",
        "  for text in text_set:\n",
        "    text_perp = 1\n",
        "    tokenized = tokenizer.texts_to_sequences(text_set)  # Tokenizo los textos\n",
        "    for text in tokenized:\n",
        "      for i in range(1, len(text)):\n",
        "        x_sequences.append(text[:i])  # Arreglos de entrada\n",
        "        y_sequences.append(text[i])   # Arreglos de salida\n",
        "\n",
        "  x_sequences = pad_sequences(x_sequences, maxlen=max_len, padding='pre', truncating='pre')\n",
        "  y_sequences = to_categorical(y_sequences, num_classes=len(token.index_word)+1)\n",
        "    x_tokenized, y_tokenized = genSequences(token, [text]) # Tokenizo y paddeo\n",
        "\n",
        "    # Hago las predicciones para los diferentes largos\n",
        "    probs = model.predict(pad_sequences(x_tokenized, maxlen=max_len), verbose=0)\n",
        "\n",
        "    # Calculo de la productoria\n",
        "    for i in range(1, len(y_tokenized)):\n",
        "      text_perp *= probs[i][np.argmax(y_tokenized[i])]\n",
        "\n",
        "    perp = np.append(perp, text_perp ** (-1/len(y_tokenized)))\n",
        "\n",
        "  return np.mean(perp)"
      ],
      "metadata": {
        "id": "FJbHtg3XpvIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelos\n",
        "Con los datos listos, estamos en condiciones de definir nuestros modelos"
      ],
      "metadata": {
        "id": "u2mQzp5h02zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Embedding, Conv1D, MaxPooling1D, BatchNormalization, GlobalMaxPooling1D, Dropout, Dense, Lambda, MaxPooling1D, Input, Concatenate, SimpleRNN, Dot, RepeatVector, TimeDistributed, Multiply, Lambda, Flatten, Activation, GRU, Reshape, Bidirectional, LSTM\n",
        "from keras.layers import Input, Concatenate, Dot, RepeatVector, TimeDistributed, Multiply\n",
        "from keras.layers import Bidirectional, LSTM, Activation, Reshape, Lambda, Dropout, GRU\n",
        "from keras.models import Sequential, Model\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.activations import softmax\n",
        "import keras.backend as K\n",
        "from keras.utils import plot_model\n",
        "\n",
        "def softMaxOverTime(x):\n",
        "    return tf.keras.activations.softmax(x,axis=1)"
      ],
      "metadata": {
        "id": "9Ks1HrAD1LpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) LSTM"
      ],
      "metadata": {
        "id": "zHbP76SB05GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_dim=100\n",
        "#vocab_size =3k+ =Cantidad de palabras en mi vocabulario\n",
        "#Max_len = 500, tamaño del contexto\n",
        "embed_dim = 300\n",
        "\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(vocab_size, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "#LSTM\n",
        "lstm_out = Bidirectional(LSTM(LSTM_dim, return_sequences=True, activation=\"tanh\"), merge_mode=\"sum\")(embedding_layer)\n",
        "ulog_attention = Dense(1, activation=\"linear\")(lstm_out)\n",
        "\n",
        "attention=Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention = TimeDistributed(RepeatVector(LSTM_dim))(attention)\n",
        "repeated_attention = Reshape([max_len, LSTM_dim])(repeated_attention)\n",
        "\n",
        "weighted_embeddings = Multiply()([repeated_attention, lstm_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n",
        "\n",
        "dense1 = Dense(256, activation='relu')(embedding_sum)\n",
        "dense2 = Dense(128, activation='relu')(dense1)\n",
        "dense_out = Dense(vocab_size, activation='softmax')(dense2)              #Elige entre las 3k palabras posibles\n",
        "\n",
        "modelLSTM = Model(input_layer, dense_out)\n",
        "adam = optimizers.Adam(learning_rate=0.01)\n",
        "modelLSTM.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['categorical_crossentropy'])\n",
        "modelLSTM.summary()"
      ],
      "metadata": {
        "id": "7eogvSR61bYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70687272-dcc4-4236-bfbd-05dcd7898167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 500)]                0         []                            \n",
            "                                                                                                  \n",
            " embedding_6 (Embedding)     (None, 500, 300)             1050300   ['input_7[0][0]']             \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirecti  (None, 500, 100)             320800    ['embedding_6[0][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " dense_24 (Dense)            (None, 500, 1)               101       ['bidirectional_4[0][0]']     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 500, 1)               0         ['dense_24[0][0]']            \n",
            "                                                                                                  \n",
            " time_distributed_6 (TimeDi  (None, 500, 100, 1)          0         ['activation_6[0][0]']        \n",
            " stributed)                                                                                       \n",
            "                                                                                                  \n",
            " reshape_6 (Reshape)         (None, 500, 100)             0         ['time_distributed_6[0][0]']  \n",
            "                                                                                                  \n",
            " multiply_6 (Multiply)       (None, 500, 100)             0         ['reshape_6[0][0]',           \n",
            "                                                                     'bidirectional_4[0][0]']     \n",
            "                                                                                                  \n",
            " lambda_6 (Lambda)           (None, 100)                  0         ['multiply_6[0][0]']          \n",
            "                                                                                                  \n",
            " dense_25 (Dense)            (None, 256)                  25856     ['lambda_6[0][0]']            \n",
            "                                                                                                  \n",
            " dense_26 (Dense)            (None, 128)                  32896     ['dense_25[0][0]']            \n",
            "                                                                                                  \n",
            " dense_27 (Dense)            (None, 3501)                 451629    ['dense_26[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1881582 (7.18 MB)\n",
            "Trainable params: 831282 (3.17 MB)\n",
            "Non-trainable params: 1050300 (4.01 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.callbacks as callbacks\n",
        "#Defino callbacks utiles\n",
        "early_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=5,\n",
        "                                   start_from_epoch=12)\n",
        "\n",
        "plateau_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.05,\n",
        "                                          patience=3)\n"
      ],
      "metadata": {
        "id": "fEWZXOLy3W17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = modelLSTM.fit(x=x_sequences,y=y_sequences,batch_size=512,epochs=70,validation_split=0.1, callbacks = [early_cb, plateau_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYXvkD9zEquT",
        "outputId": "763c604a-4ee3-4704-f251-3b29e14dfe33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "37/37 [==============================] - 24s 309ms/step - loss: 6.9819 - categorical_crossentropy: 6.9819 - val_loss: 6.6581 - val_categorical_crossentropy: 6.6581 - lr: 0.0100\n",
            "Epoch 2/70\n",
            "37/37 [==============================] - 11s 290ms/step - loss: 6.2450 - categorical_crossentropy: 6.2450 - val_loss: 6.7423 - val_categorical_crossentropy: 6.7423 - lr: 0.0100\n",
            "Epoch 3/70\n",
            "37/37 [==============================] - 10s 282ms/step - loss: 6.1885 - categorical_crossentropy: 6.1885 - val_loss: 6.6114 - val_categorical_crossentropy: 6.6114 - lr: 0.0100\n",
            "Epoch 4/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 6.0042 - categorical_crossentropy: 6.0042 - val_loss: 6.4478 - val_categorical_crossentropy: 6.4478 - lr: 0.0100\n",
            "Epoch 5/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 5.8350 - categorical_crossentropy: 5.8350 - val_loss: 6.4385 - val_categorical_crossentropy: 6.4385 - lr: 0.0100\n",
            "Epoch 6/70\n",
            "37/37 [==============================] - 10s 273ms/step - loss: 5.7072 - categorical_crossentropy: 5.7072 - val_loss: 6.3832 - val_categorical_crossentropy: 6.3832 - lr: 0.0100\n",
            "Epoch 7/70\n",
            "37/37 [==============================] - 10s 267ms/step - loss: 5.5615 - categorical_crossentropy: 5.5615 - val_loss: 6.2833 - val_categorical_crossentropy: 6.2833 - lr: 0.0100\n",
            "Epoch 8/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 5.3789 - categorical_crossentropy: 5.3789 - val_loss: 6.3554 - val_categorical_crossentropy: 6.3554 - lr: 0.0100\n",
            "Epoch 9/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 5.2333 - categorical_crossentropy: 5.2333 - val_loss: 6.3160 - val_categorical_crossentropy: 6.3160 - lr: 0.0100\n",
            "Epoch 10/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 5.1242 - categorical_crossentropy: 5.1242 - val_loss: 6.3749 - val_categorical_crossentropy: 6.3749 - lr: 0.0100\n",
            "Epoch 11/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 4.9922 - categorical_crossentropy: 4.9922 - val_loss: 6.4340 - val_categorical_crossentropy: 6.4340 - lr: 0.0100\n",
            "Epoch 12/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 4.8848 - categorical_crossentropy: 4.8848 - val_loss: 6.5156 - val_categorical_crossentropy: 6.5156 - lr: 0.0100\n",
            "Epoch 13/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 4.7715 - categorical_crossentropy: 4.7715 - val_loss: 6.5240 - val_categorical_crossentropy: 6.5240 - lr: 0.0100\n",
            "Epoch 14/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 4.6728 - categorical_crossentropy: 4.6728 - val_loss: 6.5593 - val_categorical_crossentropy: 6.5593 - lr: 0.0100\n",
            "Epoch 15/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 4.5457 - categorical_crossentropy: 4.5457 - val_loss: 6.5918 - val_categorical_crossentropy: 6.5918 - lr: 0.0100\n",
            "Epoch 16/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 4.4286 - categorical_crossentropy: 4.4286 - val_loss: 6.7713 - val_categorical_crossentropy: 6.7713 - lr: 0.0100\n",
            "Epoch 17/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 4.3246 - categorical_crossentropy: 4.3246 - val_loss: 6.8246 - val_categorical_crossentropy: 6.8246 - lr: 0.0100\n",
            "Epoch 18/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 4.2125 - categorical_crossentropy: 4.2125 - val_loss: 7.0474 - val_categorical_crossentropy: 7.0474 - lr: 0.0100\n",
            "Epoch 19/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 4.1028 - categorical_crossentropy: 4.1028 - val_loss: 7.1516 - val_categorical_crossentropy: 7.1516 - lr: 0.0100\n",
            "Epoch 20/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 3.9818 - categorical_crossentropy: 3.9818 - val_loss: 7.3916 - val_categorical_crossentropy: 7.3916 - lr: 0.0100\n",
            "Epoch 21/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 3.8586 - categorical_crossentropy: 3.8586 - val_loss: 7.5142 - val_categorical_crossentropy: 7.5142 - lr: 0.0100\n",
            "Epoch 22/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 3.7459 - categorical_crossentropy: 3.7459 - val_loss: 7.7049 - val_categorical_crossentropy: 7.7049 - lr: 0.0100\n",
            "Epoch 23/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 3.6300 - categorical_crossentropy: 3.6300 - val_loss: 8.1145 - val_categorical_crossentropy: 8.1145 - lr: 0.0100\n",
            "Epoch 24/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 3.5106 - categorical_crossentropy: 3.5106 - val_loss: 8.3424 - val_categorical_crossentropy: 8.3424 - lr: 0.0100\n",
            "Epoch 25/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 3.3938 - categorical_crossentropy: 3.3938 - val_loss: 8.4890 - val_categorical_crossentropy: 8.4890 - lr: 0.0100\n",
            "Epoch 26/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 3.2766 - categorical_crossentropy: 3.2766 - val_loss: 8.7200 - val_categorical_crossentropy: 8.7200 - lr: 0.0100\n",
            "Epoch 27/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 3.1584 - categorical_crossentropy: 3.1584 - val_loss: 9.0084 - val_categorical_crossentropy: 9.0084 - lr: 0.0100\n",
            "Epoch 28/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 3.0306 - categorical_crossentropy: 3.0306 - val_loss: 9.5031 - val_categorical_crossentropy: 9.5031 - lr: 0.0100\n",
            "Epoch 29/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 2.9144 - categorical_crossentropy: 2.9144 - val_loss: 9.7663 - val_categorical_crossentropy: 9.7663 - lr: 0.0100\n",
            "Epoch 30/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 2.8099 - categorical_crossentropy: 2.8099 - val_loss: 10.1768 - val_categorical_crossentropy: 10.1768 - lr: 0.0100\n",
            "Epoch 31/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 2.6976 - categorical_crossentropy: 2.6976 - val_loss: 10.4858 - val_categorical_crossentropy: 10.4858 - lr: 0.0100\n",
            "Epoch 32/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 2.5782 - categorical_crossentropy: 2.5782 - val_loss: 10.8722 - val_categorical_crossentropy: 10.8722 - lr: 0.0100\n",
            "Epoch 33/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 2.4753 - categorical_crossentropy: 2.4753 - val_loss: 11.3125 - val_categorical_crossentropy: 11.3125 - lr: 0.0100\n",
            "Epoch 34/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 2.3708 - categorical_crossentropy: 2.3708 - val_loss: 11.7290 - val_categorical_crossentropy: 11.7290 - lr: 0.0100\n",
            "Epoch 35/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 2.2792 - categorical_crossentropy: 2.2792 - val_loss: 12.1822 - val_categorical_crossentropy: 12.1822 - lr: 0.0100\n",
            "Epoch 36/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 2.1826 - categorical_crossentropy: 2.1826 - val_loss: 12.4960 - val_categorical_crossentropy: 12.4960 - lr: 0.0100\n",
            "Epoch 37/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 2.0592 - categorical_crossentropy: 2.0592 - val_loss: 13.0499 - val_categorical_crossentropy: 13.0499 - lr: 0.0100\n",
            "Epoch 38/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 1.9423 - categorical_crossentropy: 1.9423 - val_loss: 13.5407 - val_categorical_crossentropy: 13.5407 - lr: 0.0100\n",
            "Epoch 39/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 1.8505 - categorical_crossentropy: 1.8505 - val_loss: 13.6176 - val_categorical_crossentropy: 13.6176 - lr: 0.0100\n",
            "Epoch 40/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 1.7987 - categorical_crossentropy: 1.7987 - val_loss: 14.2840 - val_categorical_crossentropy: 14.2840 - lr: 0.0100\n",
            "Epoch 41/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 1.7590 - categorical_crossentropy: 1.7590 - val_loss: 14.4477 - val_categorical_crossentropy: 14.4477 - lr: 0.0100\n",
            "Epoch 42/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 1.6684 - categorical_crossentropy: 1.6684 - val_loss: 14.9697 - val_categorical_crossentropy: 14.9697 - lr: 0.0100\n",
            "Epoch 43/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 1.5654 - categorical_crossentropy: 1.5654 - val_loss: 15.5918 - val_categorical_crossentropy: 15.5918 - lr: 0.0100\n",
            "Epoch 44/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 1.4822 - categorical_crossentropy: 1.4822 - val_loss: 16.3475 - val_categorical_crossentropy: 16.3475 - lr: 0.0100\n",
            "Epoch 45/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 1.4014 - categorical_crossentropy: 1.4014 - val_loss: 16.4495 - val_categorical_crossentropy: 16.4495 - lr: 0.0100\n",
            "Epoch 46/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 1.3144 - categorical_crossentropy: 1.3144 - val_loss: 16.8762 - val_categorical_crossentropy: 16.8762 - lr: 0.0100\n",
            "Epoch 47/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 1.2475 - categorical_crossentropy: 1.2475 - val_loss: 17.2628 - val_categorical_crossentropy: 17.2628 - lr: 0.0100\n",
            "Epoch 48/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 1.1890 - categorical_crossentropy: 1.1890 - val_loss: 17.9595 - val_categorical_crossentropy: 17.9595 - lr: 0.0100\n",
            "Epoch 49/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 1.1278 - categorical_crossentropy: 1.1278 - val_loss: 18.5173 - val_categorical_crossentropy: 18.5173 - lr: 0.0100\n",
            "Epoch 50/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 1.0738 - categorical_crossentropy: 1.0738 - val_loss: 18.8026 - val_categorical_crossentropy: 18.8026 - lr: 0.0100\n",
            "Epoch 51/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 1.0451 - categorical_crossentropy: 1.0451 - val_loss: 19.3094 - val_categorical_crossentropy: 19.3094 - lr: 0.0100\n",
            "Epoch 52/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 1.0283 - categorical_crossentropy: 1.0283 - val_loss: 19.6059 - val_categorical_crossentropy: 19.6059 - lr: 0.0100\n",
            "Epoch 53/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 0.9647 - categorical_crossentropy: 0.9647 - val_loss: 19.7974 - val_categorical_crossentropy: 19.7974 - lr: 0.0100\n",
            "Epoch 54/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 0.9406 - categorical_crossentropy: 0.9406 - val_loss: 20.4858 - val_categorical_crossentropy: 20.4858 - lr: 0.0100\n",
            "Epoch 55/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 0.9431 - categorical_crossentropy: 0.9431 - val_loss: 20.6910 - val_categorical_crossentropy: 20.6910 - lr: 0.0100\n",
            "Epoch 56/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 0.8961 - categorical_crossentropy: 0.8961 - val_loss: 20.8689 - val_categorical_crossentropy: 20.8689 - lr: 0.0100\n",
            "Epoch 57/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 0.8453 - categorical_crossentropy: 0.8453 - val_loss: 21.3726 - val_categorical_crossentropy: 21.3726 - lr: 0.0100\n",
            "Epoch 58/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 0.7786 - categorical_crossentropy: 0.7786 - val_loss: 21.7446 - val_categorical_crossentropy: 21.7446 - lr: 0.0100\n",
            "Epoch 59/70\n",
            "37/37 [==============================] - 10s 271ms/step - loss: 0.7702 - categorical_crossentropy: 0.7702 - val_loss: 22.5293 - val_categorical_crossentropy: 22.5293 - lr: 0.0100\n",
            "Epoch 60/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 0.7195 - categorical_crossentropy: 0.7195 - val_loss: 23.0551 - val_categorical_crossentropy: 23.0551 - lr: 0.0100\n",
            "Epoch 61/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 0.7122 - categorical_crossentropy: 0.7122 - val_loss: 23.7041 - val_categorical_crossentropy: 23.7041 - lr: 0.0100\n",
            "Epoch 62/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 0.6536 - categorical_crossentropy: 0.6536 - val_loss: 23.5902 - val_categorical_crossentropy: 23.5902 - lr: 0.0100\n",
            "Epoch 63/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 0.6570 - categorical_crossentropy: 0.6570 - val_loss: 24.2453 - val_categorical_crossentropy: 24.2453 - lr: 0.0100\n",
            "Epoch 64/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 0.6362 - categorical_crossentropy: 0.6362 - val_loss: 24.5825 - val_categorical_crossentropy: 24.5825 - lr: 0.0100\n",
            "Epoch 65/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 0.6280 - categorical_crossentropy: 0.6280 - val_loss: 24.7696 - val_categorical_crossentropy: 24.7696 - lr: 0.0100\n",
            "Epoch 66/70\n",
            "37/37 [==============================] - 10s 269ms/step - loss: 0.5458 - categorical_crossentropy: 0.5458 - val_loss: 25.5579 - val_categorical_crossentropy: 25.5579 - lr: 0.0100\n",
            "Epoch 67/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 0.5423 - categorical_crossentropy: 0.5423 - val_loss: 26.1380 - val_categorical_crossentropy: 26.1380 - lr: 0.0100\n",
            "Epoch 68/70\n",
            "37/37 [==============================] - 10s 277ms/step - loss: 0.5266 - categorical_crossentropy: 0.5266 - val_loss: 25.6130 - val_categorical_crossentropy: 25.6130 - lr: 0.0100\n",
            "Epoch 69/70\n",
            "37/37 [==============================] - 10s 270ms/step - loss: 0.5000 - categorical_crossentropy: 0.5000 - val_loss: 26.6173 - val_categorical_crossentropy: 26.6173 - lr: 0.0100\n",
            "Epoch 70/70\n",
            "37/37 [==============================] - 10s 276ms/step - loss: 0.4941 - categorical_crossentropy: 0.4941 - val_loss: 26.2752 - val_categorical_crossentropy: 26.2752 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelLSTM.save(\"/content/drive/MyDrive/Colab Notebooks/modelLM-LSTM.h5\")"
      ],
      "metadata": {
        "id": "JxX0orYoQiEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8963ab4-d2cd-4e33-d46b-aaafce6ee60d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = perplexity(modelLSTM, x_sequences[:100], token.index_to_text(y_sequences[:100]), vocab_size, embedding_matrix)\n",
        "print(\"Perplexity:\", Perplexity(trainset[::3], token, model))\n",
        "print(\"Perplejidad del modelo:\", perplexity)"
      ],
      "metadata": {
        "id": "MuAbMCBbp1Rr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "e76056bc-6a1d-4c8a-ffc2-c4d4e86a911d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-01be2be25d23>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Perplexity:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPerplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Perplejidad del modelo:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-af381d58b3fc>\u001b[0m in \u001b[0;36mperplexity\u001b[0;34m(model, x_sequences, y_indices, nwords, embedding_matrix)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpredicted_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mword_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredicted_probs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#sequence_perplexity = 2 ** (-np.log2(word_prob))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: arrays used as indices must be of integer (or boolean) type"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) CNN"
      ],
      "metadata": {
        "id": "6cKzG1Fr07yS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value_dim=100\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(vocab_size, embed_dim, weights=[embedding_matrix], input_length=max_len, trainable=False)(input_layer)\n",
        "#CNN\n",
        "cnn_out = (Conv1D(value_dim, kernel_size=3, activation=\"relu\", padding=\"same\"))(embedding_layer)\n",
        "ulog_attention = Dense(1, activation=\"linear\")(cnn_out)\n",
        "attention = Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention = TimeDistributed(RepeatVector(value_dim))(attention)\n",
        "repeated_attention = Reshape([max_len, value_dim])(repeated_attention)\n",
        "weighted_embeddings = Multiply()([repeated_attention, cnn_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n",
        "\n",
        "dense1 = Dense(256, activation='relu')(embedding_sum)\n",
        "dense2 = Dense(128, activation='relu')(dense1)\n",
        "dense_out = Dense(vocab_size, activation='softmax')(dense2)              #Elige entre las 3k palabras posibles\n",
        "\n",
        "modelCNN = Model(input_layer, dense_out)\n",
        "adam = optimizers.Adam(learning_rate=0.01)\n",
        "modelCNN.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=adam,\n",
        "                 metrics=['categorical_crossentropy'])\n"
      ],
      "metadata": {
        "id": "8HRu2QRx3ysx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=5,\n",
        "                                   start_from_epoch=12)\n",
        "\n",
        "plateau_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.05,\n",
        "                                          patience=3)"
      ],
      "metadata": {
        "id": "8st3hgPhZKz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = modelCNN.fit(x_sequences,y_sequences,batch_size=512,epochs=70,validation_split=0.1, callbacks = [early_cb, plateau_cb])"
      ],
      "metadata": {
        "id": "vorRmkTRZMmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0532dd0-ae6e-4100-ac29-460a918e0dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "37/37 [==============================] - 10s 91ms/step - loss: 6.7384 - categorical_crossentropy: 6.7384 - val_loss: 6.5684 - val_categorical_crossentropy: 6.5684 - lr: 0.0100\n",
            "Epoch 2/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 6.2317 - categorical_crossentropy: 6.2317 - val_loss: 6.6628 - val_categorical_crossentropy: 6.6628 - lr: 0.0100\n",
            "Epoch 3/70\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 6.2082 - categorical_crossentropy: 6.2082 - val_loss: 6.6899 - val_categorical_crossentropy: 6.6899 - lr: 0.0100\n",
            "Epoch 4/70\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 6.2058 - categorical_crossentropy: 6.2058 - val_loss: 6.6981 - val_categorical_crossentropy: 6.6981 - lr: 0.0100\n",
            "Epoch 5/70\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 6.2047 - categorical_crossentropy: 6.2047 - val_loss: 6.7589 - val_categorical_crossentropy: 6.7589 - lr: 0.0100\n",
            "Epoch 6/70\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 6.1956 - categorical_crossentropy: 6.1956 - val_loss: 6.8022 - val_categorical_crossentropy: 6.8022 - lr: 0.0100\n",
            "Epoch 7/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 6.1808 - categorical_crossentropy: 6.1808 - val_loss: 6.8330 - val_categorical_crossentropy: 6.8330 - lr: 0.0100\n",
            "Epoch 8/70\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 6.1532 - categorical_crossentropy: 6.1532 - val_loss: 6.8380 - val_categorical_crossentropy: 6.8380 - lr: 0.0100\n",
            "Epoch 9/70\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 6.1311 - categorical_crossentropy: 6.1311 - val_loss: 6.9032 - val_categorical_crossentropy: 6.9032 - lr: 0.0100\n",
            "Epoch 10/70\n",
            "37/37 [==============================] - 3s 78ms/step - loss: 6.1060 - categorical_crossentropy: 6.1060 - val_loss: 6.9873 - val_categorical_crossentropy: 6.9873 - lr: 0.0100\n",
            "Epoch 11/70\n",
            "37/37 [==============================] - 3s 93ms/step - loss: 6.0958 - categorical_crossentropy: 6.0958 - val_loss: 6.9502 - val_categorical_crossentropy: 6.9502 - lr: 0.0100\n",
            "Epoch 12/70\n",
            "37/37 [==============================] - 3s 91ms/step - loss: 6.0693 - categorical_crossentropy: 6.0693 - val_loss: 7.0221 - val_categorical_crossentropy: 7.0221 - lr: 0.0100\n",
            "Epoch 13/70\n",
            "37/37 [==============================] - 3s 82ms/step - loss: 6.0575 - categorical_crossentropy: 6.0575 - val_loss: 7.0199 - val_categorical_crossentropy: 7.0199 - lr: 0.0100\n",
            "Epoch 14/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 6.0308 - categorical_crossentropy: 6.0308 - val_loss: 6.9710 - val_categorical_crossentropy: 6.9710 - lr: 0.0100\n",
            "Epoch 15/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 5.9950 - categorical_crossentropy: 5.9950 - val_loss: 6.9030 - val_categorical_crossentropy: 6.9030 - lr: 0.0100\n",
            "Epoch 16/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 5.9476 - categorical_crossentropy: 5.9476 - val_loss: 6.7305 - val_categorical_crossentropy: 6.7305 - lr: 0.0100\n",
            "Epoch 17/70\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 5.7928 - categorical_crossentropy: 5.7928 - val_loss: 6.8539 - val_categorical_crossentropy: 6.8539 - lr: 0.0100\n",
            "Epoch 18/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 5.6779 - categorical_crossentropy: 5.6779 - val_loss: 6.8142 - val_categorical_crossentropy: 6.8142 - lr: 0.0100\n",
            "Epoch 19/70\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 5.6154 - categorical_crossentropy: 5.6154 - val_loss: 6.9025 - val_categorical_crossentropy: 6.9025 - lr: 0.0100\n",
            "Epoch 20/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 5.5356 - categorical_crossentropy: 5.5356 - val_loss: 6.9879 - val_categorical_crossentropy: 6.9879 - lr: 0.0100\n",
            "Epoch 21/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 5.4556 - categorical_crossentropy: 5.4556 - val_loss: 6.8951 - val_categorical_crossentropy: 6.8951 - lr: 0.0100\n",
            "Epoch 22/70\n",
            "37/37 [==============================] - 3s 69ms/step - loss: 5.3673 - categorical_crossentropy: 5.3673 - val_loss: 7.1936 - val_categorical_crossentropy: 7.1936 - lr: 0.0100\n",
            "Epoch 23/70\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 5.2894 - categorical_crossentropy: 5.2894 - val_loss: 7.0050 - val_categorical_crossentropy: 7.0050 - lr: 0.0100\n",
            "Epoch 24/70\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 5.2272 - categorical_crossentropy: 5.2272 - val_loss: 7.1321 - val_categorical_crossentropy: 7.1321 - lr: 0.0100\n",
            "Epoch 25/70\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 5.1418 - categorical_crossentropy: 5.1418 - val_loss: 7.3337 - val_categorical_crossentropy: 7.3337 - lr: 0.0100\n",
            "Epoch 26/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 5.0781 - categorical_crossentropy: 5.0781 - val_loss: 7.5186 - val_categorical_crossentropy: 7.5186 - lr: 0.0100\n",
            "Epoch 27/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 4.9819 - categorical_crossentropy: 4.9819 - val_loss: 7.5317 - val_categorical_crossentropy: 7.5317 - lr: 0.0100\n",
            "Epoch 28/70\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 4.8881 - categorical_crossentropy: 4.8881 - val_loss: 7.5221 - val_categorical_crossentropy: 7.5221 - lr: 0.0100\n",
            "Epoch 29/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 4.8153 - categorical_crossentropy: 4.8153 - val_loss: 7.5210 - val_categorical_crossentropy: 7.5210 - lr: 0.0100\n",
            "Epoch 30/70\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 4.7225 - categorical_crossentropy: 4.7225 - val_loss: 7.7504 - val_categorical_crossentropy: 7.7504 - lr: 0.0100\n",
            "Epoch 31/70\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 4.6456 - categorical_crossentropy: 4.6456 - val_loss: 7.9243 - val_categorical_crossentropy: 7.9243 - lr: 0.0100\n",
            "Epoch 32/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 4.5652 - categorical_crossentropy: 4.5652 - val_loss: 7.8864 - val_categorical_crossentropy: 7.8864 - lr: 0.0100\n",
            "Epoch 33/70\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 4.4850 - categorical_crossentropy: 4.4850 - val_loss: 8.0126 - val_categorical_crossentropy: 8.0126 - lr: 0.0100\n",
            "Epoch 34/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 4.4120 - categorical_crossentropy: 4.4120 - val_loss: 8.0162 - val_categorical_crossentropy: 8.0162 - lr: 0.0100\n",
            "Epoch 35/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 4.3502 - categorical_crossentropy: 4.3502 - val_loss: 8.3635 - val_categorical_crossentropy: 8.3635 - lr: 0.0100\n",
            "Epoch 36/70\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 4.2786 - categorical_crossentropy: 4.2786 - val_loss: 8.4413 - val_categorical_crossentropy: 8.4413 - lr: 0.0100\n",
            "Epoch 37/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 4.2140 - categorical_crossentropy: 4.2140 - val_loss: 8.5701 - val_categorical_crossentropy: 8.5701 - lr: 0.0100\n",
            "Epoch 38/70\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 4.1566 - categorical_crossentropy: 4.1566 - val_loss: 8.6533 - val_categorical_crossentropy: 8.6533 - lr: 0.0100\n",
            "Epoch 39/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 4.0927 - categorical_crossentropy: 4.0927 - val_loss: 8.6157 - val_categorical_crossentropy: 8.6157 - lr: 0.0100\n",
            "Epoch 40/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 4.0454 - categorical_crossentropy: 4.0454 - val_loss: 8.8813 - val_categorical_crossentropy: 8.8813 - lr: 0.0100\n",
            "Epoch 41/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 3.9771 - categorical_crossentropy: 3.9771 - val_loss: 8.9775 - val_categorical_crossentropy: 8.9775 - lr: 0.0100\n",
            "Epoch 42/70\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 3.9461 - categorical_crossentropy: 3.9461 - val_loss: 9.0841 - val_categorical_crossentropy: 9.0841 - lr: 0.0100\n",
            "Epoch 43/70\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 3.8858 - categorical_crossentropy: 3.8858 - val_loss: 9.1782 - val_categorical_crossentropy: 9.1782 - lr: 0.0100\n",
            "Epoch 44/70\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 3.8289 - categorical_crossentropy: 3.8289 - val_loss: 9.6801 - val_categorical_crossentropy: 9.6801 - lr: 0.0100\n",
            "Epoch 45/70\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 3.7749 - categorical_crossentropy: 3.7749 - val_loss: 9.5576 - val_categorical_crossentropy: 9.5576 - lr: 0.0100\n",
            "Epoch 46/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 3.7162 - categorical_crossentropy: 3.7162 - val_loss: 9.6099 - val_categorical_crossentropy: 9.6099 - lr: 0.0100\n",
            "Epoch 47/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 3.6875 - categorical_crossentropy: 3.6875 - val_loss: 9.7145 - val_categorical_crossentropy: 9.7145 - lr: 0.0100\n",
            "Epoch 48/70\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 3.6465 - categorical_crossentropy: 3.6465 - val_loss: 10.0134 - val_categorical_crossentropy: 10.0134 - lr: 0.0100\n",
            "Epoch 49/70\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 3.6029 - categorical_crossentropy: 3.6029 - val_loss: 10.2902 - val_categorical_crossentropy: 10.2902 - lr: 0.0100\n",
            "Epoch 50/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 3.5533 - categorical_crossentropy: 3.5533 - val_loss: 10.6246 - val_categorical_crossentropy: 10.6246 - lr: 0.0100\n",
            "Epoch 51/70\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 3.5105 - categorical_crossentropy: 3.5105 - val_loss: 10.2624 - val_categorical_crossentropy: 10.2624 - lr: 0.0100\n",
            "Epoch 52/70\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 3.4682 - categorical_crossentropy: 3.4682 - val_loss: 10.3996 - val_categorical_crossentropy: 10.3996 - lr: 0.0100\n",
            "Epoch 53/70\n",
            "37/37 [==============================] - 3s 72ms/step - loss: 3.4466 - categorical_crossentropy: 3.4466 - val_loss: 10.7455 - val_categorical_crossentropy: 10.7455 - lr: 0.0100\n",
            "Epoch 54/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 3.4218 - categorical_crossentropy: 3.4218 - val_loss: 11.1595 - val_categorical_crossentropy: 11.1595 - lr: 0.0100\n",
            "Epoch 55/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 3.3679 - categorical_crossentropy: 3.3679 - val_loss: 10.7853 - val_categorical_crossentropy: 10.7853 - lr: 0.0100\n",
            "Epoch 56/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 3.3172 - categorical_crossentropy: 3.3172 - val_loss: 11.0723 - val_categorical_crossentropy: 11.0723 - lr: 0.0100\n",
            "Epoch 57/70\n",
            "37/37 [==============================] - 3s 69ms/step - loss: 3.3013 - categorical_crossentropy: 3.3013 - val_loss: 11.1320 - val_categorical_crossentropy: 11.1320 - lr: 0.0100\n",
            "Epoch 58/70\n",
            "37/37 [==============================] - 3s 69ms/step - loss: 3.2612 - categorical_crossentropy: 3.2612 - val_loss: 11.2276 - val_categorical_crossentropy: 11.2276 - lr: 0.0100\n",
            "Epoch 59/70\n",
            "37/37 [==============================] - 3s 71ms/step - loss: 3.2165 - categorical_crossentropy: 3.2165 - val_loss: 11.8912 - val_categorical_crossentropy: 11.8912 - lr: 0.0100\n",
            "Epoch 60/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 3.1994 - categorical_crossentropy: 3.1994 - val_loss: 11.9567 - val_categorical_crossentropy: 11.9567 - lr: 0.0100\n",
            "Epoch 61/70\n",
            "37/37 [==============================] - 3s 74ms/step - loss: 3.1532 - categorical_crossentropy: 3.1532 - val_loss: 12.0872 - val_categorical_crossentropy: 12.0872 - lr: 0.0100\n",
            "Epoch 62/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 3.1478 - categorical_crossentropy: 3.1478 - val_loss: 12.5129 - val_categorical_crossentropy: 12.5129 - lr: 0.0100\n",
            "Epoch 63/70\n",
            "37/37 [==============================] - 3s 69ms/step - loss: 3.1074 - categorical_crossentropy: 3.1074 - val_loss: 12.9706 - val_categorical_crossentropy: 12.9706 - lr: 0.0100\n",
            "Epoch 64/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 3.0594 - categorical_crossentropy: 3.0594 - val_loss: 12.6208 - val_categorical_crossentropy: 12.6208 - lr: 0.0100\n",
            "Epoch 65/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 3.0411 - categorical_crossentropy: 3.0411 - val_loss: 12.4209 - val_categorical_crossentropy: 12.4209 - lr: 0.0100\n",
            "Epoch 66/70\n",
            "37/37 [==============================] - 3s 75ms/step - loss: 3.0127 - categorical_crossentropy: 3.0127 - val_loss: 12.9366 - val_categorical_crossentropy: 12.9366 - lr: 0.0100\n",
            "Epoch 67/70\n",
            "37/37 [==============================] - 3s 73ms/step - loss: 2.9838 - categorical_crossentropy: 2.9838 - val_loss: 13.6908 - val_categorical_crossentropy: 13.6908 - lr: 0.0100\n",
            "Epoch 68/70\n",
            "37/37 [==============================] - 3s 70ms/step - loss: 2.9886 - categorical_crossentropy: 2.9886 - val_loss: 13.7035 - val_categorical_crossentropy: 13.7035 - lr: 0.0100\n",
            "Epoch 69/70\n",
            "37/37 [==============================] - 3s 69ms/step - loss: 2.9725 - categorical_crossentropy: 2.9725 - val_loss: 13.3828 - val_categorical_crossentropy: 13.3828 - lr: 0.0100\n",
            "Epoch 70/70\n",
            "37/37 [==============================] - 3s 69ms/step - loss: 2.9542 - categorical_crossentropy: 2.9542 - val_loss: 13.2302 - val_categorical_crossentropy: 13.2302 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelCNN.save(\"/content/drive/MyDrive/Colab Notebooks/modelLM-CNN.h5\")"
      ],
      "metadata": {
        "id": "_UEWwL5AQyKV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c394e5d2-b3f1-468d-ad0b-f2b1a4f5b78f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(np.argmax(y_sequences[:100])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7NeRBdzfurP",
        "outputId": "37f866bc-0d51-416d-cdef-1a5af9edabe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.int64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = perplexity(modelCNN, x_sequences[:100], np.argmax(y_sequences[:100]), vocab_size, embedding_matrix)\n",
        "print(\"Perplejidad del modelo:\", perplexity)"
      ],
      "metadata": {
        "id": "UYiANX0np3Z0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "a9e25fc0-5222-4306-92d9-90fa03a62d9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-b67448369235>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Perplejidad del modelo:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperplexity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-af381d58b3fc>\u001b[0m in \u001b[0;36mperplexity\u001b[0;34m(model, x_sequences, y_indices, nwords, embedding_matrix)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mx_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0my_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpredicted_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_seq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) GRU"
      ],
      "metadata": {
        "id": "d2m8MjV71EQC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "value_dim=100\n",
        "\n",
        "input_layer = Input(shape=(max_len,))\n",
        "embedding_layer = Embedding(vocab_size, embed_dim, input_length=max_len, trainable=False)(input_layer)\n",
        "#GRU\n",
        "gru_out = Bidirectional(GRU(value_dim, return_sequences=True, activation=\"tanh\"), merge_mode=\"sum\")(embedding_layer)\n",
        "\n",
        "ulog_attention = Dense(1, activation=\"linear\")(gru_out)\n",
        "attention = Activation(softMaxOverTime)(ulog_attention)\n",
        "repeated_attention = TimeDistributed(RepeatVector(value_dim))(attention)\n",
        "repeated_attention = Reshape([max_len, value_dim])(repeated_attention)\n",
        "weighted_embeddings = Multiply()([repeated_attention, gru_out])\n",
        "embedding_sum = Lambda(lambda x: K.sum(x, axis=1))(weighted_embeddings)\n",
        "\n",
        "dense1 = Dense(256, activation='relu')(embedding_sum)\n",
        "dense2 = Dense(128, activation='relu')(dense1)\n",
        "dense_out = Dense(vocab_size, activation='softmax')(dense2)              #Elige entre las 3k palabras posibles\n",
        "\n",
        "modelGRU = Model(input_layer, dense_out)\n",
        "adam = optimizers.Adam(learning_rate=0.01)\n",
        "modelGRU.compile(loss='categorical_crossentropy',\n",
        "                 optimizer=adam,\n",
        "                 metrics=['categorical_crossentropy'])"
      ],
      "metadata": {
        "id": "BGUG6BDx3v2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=5,\n",
        "                                   start_from_epoch=12)\n",
        "\n",
        "plateau_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.05,\n",
        "                                          patience=3)\n",
        "hist = modelGRU.fit(x_sequences,y_sequences,batch_size=512,epochs=70,validation_split=0.1, callbacks = [early_cb, plateau_cb])"
      ],
      "metadata": {
        "id": "WEiqjgD1ZOpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80657695-4429-4f3f-bb57-8ac24cc533d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "37/37 [==============================] - 14s 257ms/step - loss: 6.9555 - categorical_crossentropy: 6.9555 - val_loss: 6.6124 - val_categorical_crossentropy: 6.6124 - lr: 0.0100\n",
            "Epoch 2/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 6.2607 - categorical_crossentropy: 6.2607 - val_loss: 6.7452 - val_categorical_crossentropy: 6.7452 - lr: 0.0100\n",
            "Epoch 3/70\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 6.2209 - categorical_crossentropy: 6.2209 - val_loss: 6.6902 - val_categorical_crossentropy: 6.6902 - lr: 0.0100\n",
            "Epoch 4/70\n",
            "37/37 [==============================] - 9s 246ms/step - loss: 6.2082 - categorical_crossentropy: 6.2082 - val_loss: 6.6909 - val_categorical_crossentropy: 6.6909 - lr: 0.0100\n",
            "Epoch 5/70\n",
            "37/37 [==============================] - 9s 236ms/step - loss: 6.1905 - categorical_crossentropy: 6.1905 - val_loss: 6.8126 - val_categorical_crossentropy: 6.8126 - lr: 0.0100\n",
            "Epoch 6/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 6.1800 - categorical_crossentropy: 6.1800 - val_loss: 6.7292 - val_categorical_crossentropy: 6.7292 - lr: 0.0100\n",
            "Epoch 7/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 6.1614 - categorical_crossentropy: 6.1614 - val_loss: 6.8319 - val_categorical_crossentropy: 6.8319 - lr: 0.0100\n",
            "Epoch 8/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 6.1491 - categorical_crossentropy: 6.1491 - val_loss: 6.7953 - val_categorical_crossentropy: 6.7953 - lr: 0.0100\n",
            "Epoch 9/70\n",
            "37/37 [==============================] - 8s 227ms/step - loss: 6.1145 - categorical_crossentropy: 6.1145 - val_loss: 6.7550 - val_categorical_crossentropy: 6.7550 - lr: 0.0100\n",
            "Epoch 10/70\n",
            "37/37 [==============================] - 8s 228ms/step - loss: 6.0598 - categorical_crossentropy: 6.0598 - val_loss: 6.6977 - val_categorical_crossentropy: 6.6977 - lr: 0.0100\n",
            "Epoch 11/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 6.0262 - categorical_crossentropy: 6.0262 - val_loss: 6.7449 - val_categorical_crossentropy: 6.7449 - lr: 0.0100\n",
            "Epoch 12/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 5.9652 - categorical_crossentropy: 5.9652 - val_loss: 6.6498 - val_categorical_crossentropy: 6.6498 - lr: 0.0100\n",
            "Epoch 13/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 5.8158 - categorical_crossentropy: 5.8158 - val_loss: 6.6875 - val_categorical_crossentropy: 6.6875 - lr: 0.0100\n",
            "Epoch 14/70\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 5.7049 - categorical_crossentropy: 5.7049 - val_loss: 6.6663 - val_categorical_crossentropy: 6.6663 - lr: 0.0100\n",
            "Epoch 15/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 5.6275 - categorical_crossentropy: 5.6275 - val_loss: 6.6221 - val_categorical_crossentropy: 6.6221 - lr: 0.0100\n",
            "Epoch 16/70\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 5.5585 - categorical_crossentropy: 5.5585 - val_loss: 6.6820 - val_categorical_crossentropy: 6.6820 - lr: 0.0100\n",
            "Epoch 17/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 5.4773 - categorical_crossentropy: 5.4773 - val_loss: 6.6659 - val_categorical_crossentropy: 6.6659 - lr: 0.0100\n",
            "Epoch 18/70\n",
            "37/37 [==============================] - 8s 230ms/step - loss: 5.3663 - categorical_crossentropy: 5.3663 - val_loss: 6.7201 - val_categorical_crossentropy: 6.7201 - lr: 0.0100\n",
            "Epoch 19/70\n",
            "37/37 [==============================] - 9s 246ms/step - loss: 5.2361 - categorical_crossentropy: 5.2361 - val_loss: 6.7570 - val_categorical_crossentropy: 6.7570 - lr: 0.0100\n",
            "Epoch 20/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 5.1258 - categorical_crossentropy: 5.1258 - val_loss: 6.7502 - val_categorical_crossentropy: 6.7502 - lr: 0.0100\n",
            "Epoch 21/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 5.0348 - categorical_crossentropy: 5.0348 - val_loss: 6.8347 - val_categorical_crossentropy: 6.8347 - lr: 0.0100\n",
            "Epoch 22/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 4.9468 - categorical_crossentropy: 4.9468 - val_loss: 7.0220 - val_categorical_crossentropy: 7.0220 - lr: 0.0100\n",
            "Epoch 23/70\n",
            "37/37 [==============================] - 8s 230ms/step - loss: 4.8548 - categorical_crossentropy: 4.8548 - val_loss: 7.0571 - val_categorical_crossentropy: 7.0571 - lr: 0.0100\n",
            "Epoch 24/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 4.7628 - categorical_crossentropy: 4.7628 - val_loss: 7.1486 - val_categorical_crossentropy: 7.1486 - lr: 0.0100\n",
            "Epoch 25/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 4.6829 - categorical_crossentropy: 4.6829 - val_loss: 7.3358 - val_categorical_crossentropy: 7.3358 - lr: 0.0100\n",
            "Epoch 26/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 4.5928 - categorical_crossentropy: 4.5928 - val_loss: 7.3356 - val_categorical_crossentropy: 7.3356 - lr: 0.0100\n",
            "Epoch 27/70\n",
            "37/37 [==============================] - 9s 240ms/step - loss: 4.5018 - categorical_crossentropy: 4.5018 - val_loss: 7.6659 - val_categorical_crossentropy: 7.6659 - lr: 0.0100\n",
            "Epoch 28/70\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 4.4190 - categorical_crossentropy: 4.4190 - val_loss: 7.6442 - val_categorical_crossentropy: 7.6442 - lr: 0.0100\n",
            "Epoch 29/70\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 4.3183 - categorical_crossentropy: 4.3183 - val_loss: 7.6757 - val_categorical_crossentropy: 7.6757 - lr: 0.0100\n",
            "Epoch 30/70\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 4.2364 - categorical_crossentropy: 4.2364 - val_loss: 8.0192 - val_categorical_crossentropy: 8.0192 - lr: 0.0100\n",
            "Epoch 31/70\n",
            "37/37 [==============================] - 9s 235ms/step - loss: 4.1397 - categorical_crossentropy: 4.1397 - val_loss: 8.2631 - val_categorical_crossentropy: 8.2631 - lr: 0.0100\n",
            "Epoch 32/70\n",
            "37/37 [==============================] - 9s 239ms/step - loss: 4.0578 - categorical_crossentropy: 4.0578 - val_loss: 8.3589 - val_categorical_crossentropy: 8.3589 - lr: 0.0100\n",
            "Epoch 33/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 3.9797 - categorical_crossentropy: 3.9797 - val_loss: 8.4608 - val_categorical_crossentropy: 8.4608 - lr: 0.0100\n",
            "Epoch 34/70\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 3.8866 - categorical_crossentropy: 3.8866 - val_loss: 8.7087 - val_categorical_crossentropy: 8.7087 - lr: 0.0100\n",
            "Epoch 35/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 3.7829 - categorical_crossentropy: 3.7829 - val_loss: 9.2193 - val_categorical_crossentropy: 9.2193 - lr: 0.0100\n",
            "Epoch 36/70\n",
            "37/37 [==============================] - 8s 230ms/step - loss: 3.6856 - categorical_crossentropy: 3.6856 - val_loss: 9.1630 - val_categorical_crossentropy: 9.1630 - lr: 0.0100\n",
            "Epoch 37/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 3.5791 - categorical_crossentropy: 3.5791 - val_loss: 9.4646 - val_categorical_crossentropy: 9.4646 - lr: 0.0100\n",
            "Epoch 38/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 3.5383 - categorical_crossentropy: 3.5383 - val_loss: 9.5064 - val_categorical_crossentropy: 9.5064 - lr: 0.0100\n",
            "Epoch 39/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 3.4162 - categorical_crossentropy: 3.4162 - val_loss: 10.1048 - val_categorical_crossentropy: 10.1048 - lr: 0.0100\n",
            "Epoch 40/70\n",
            "37/37 [==============================] - 9s 249ms/step - loss: 3.3437 - categorical_crossentropy: 3.3437 - val_loss: 10.4725 - val_categorical_crossentropy: 10.4725 - lr: 0.0100\n",
            "Epoch 41/70\n",
            "37/37 [==============================] - 9s 230ms/step - loss: 3.2234 - categorical_crossentropy: 3.2234 - val_loss: 10.6905 - val_categorical_crossentropy: 10.6905 - lr: 0.0100\n",
            "Epoch 42/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 3.1453 - categorical_crossentropy: 3.1453 - val_loss: 10.8904 - val_categorical_crossentropy: 10.8904 - lr: 0.0100\n",
            "Epoch 43/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 3.0236 - categorical_crossentropy: 3.0236 - val_loss: 11.1518 - val_categorical_crossentropy: 11.1518 - lr: 0.0100\n",
            "Epoch 44/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 2.9403 - categorical_crossentropy: 2.9403 - val_loss: 11.6004 - val_categorical_crossentropy: 11.6004 - lr: 0.0100\n",
            "Epoch 45/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 2.8476 - categorical_crossentropy: 2.8476 - val_loss: 11.8477 - val_categorical_crossentropy: 11.8477 - lr: 0.0100\n",
            "Epoch 46/70\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 2.8049 - categorical_crossentropy: 2.8049 - val_loss: 11.8808 - val_categorical_crossentropy: 11.8808 - lr: 0.0100\n",
            "Epoch 47/70\n",
            "37/37 [==============================] - 9s 232ms/step - loss: 2.7114 - categorical_crossentropy: 2.7114 - val_loss: 12.5119 - val_categorical_crossentropy: 12.5119 - lr: 0.0100\n",
            "Epoch 48/70\n",
            "37/37 [==============================] - 8s 230ms/step - loss: 2.6180 - categorical_crossentropy: 2.6180 - val_loss: 12.9239 - val_categorical_crossentropy: 12.9239 - lr: 0.0100\n",
            "Epoch 49/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 2.5613 - categorical_crossentropy: 2.5613 - val_loss: 12.9837 - val_categorical_crossentropy: 12.9837 - lr: 0.0100\n",
            "Epoch 50/70\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 2.4489 - categorical_crossentropy: 2.4489 - val_loss: 13.4248 - val_categorical_crossentropy: 13.4248 - lr: 0.0100\n",
            "Epoch 51/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 2.3767 - categorical_crossentropy: 2.3767 - val_loss: 13.8098 - val_categorical_crossentropy: 13.8098 - lr: 0.0100\n",
            "Epoch 52/70\n",
            "37/37 [==============================] - 9s 241ms/step - loss: 2.2824 - categorical_crossentropy: 2.2824 - val_loss: 13.9643 - val_categorical_crossentropy: 13.9643 - lr: 0.0100\n",
            "Epoch 53/70\n",
            "37/37 [==============================] - 9s 242ms/step - loss: 2.2179 - categorical_crossentropy: 2.2179 - val_loss: 14.6582 - val_categorical_crossentropy: 14.6582 - lr: 0.0100\n",
            "Epoch 54/70\n",
            "37/37 [==============================] - 9s 231ms/step - loss: 2.1617 - categorical_crossentropy: 2.1617 - val_loss: 14.6094 - val_categorical_crossentropy: 14.6094 - lr: 0.0100\n",
            "Epoch 55/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 2.0933 - categorical_crossentropy: 2.0933 - val_loss: 15.4263 - val_categorical_crossentropy: 15.4263 - lr: 0.0100\n",
            "Epoch 56/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 2.1114 - categorical_crossentropy: 2.1114 - val_loss: 15.5577 - val_categorical_crossentropy: 15.5577 - lr: 0.0100\n",
            "Epoch 57/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 2.0265 - categorical_crossentropy: 2.0265 - val_loss: 15.6853 - val_categorical_crossentropy: 15.6853 - lr: 0.0100\n",
            "Epoch 58/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 1.8907 - categorical_crossentropy: 1.8907 - val_loss: 16.3076 - val_categorical_crossentropy: 16.3076 - lr: 0.0100\n",
            "Epoch 59/70\n",
            "37/37 [==============================] - 8s 230ms/step - loss: 1.8389 - categorical_crossentropy: 1.8389 - val_loss: 16.8574 - val_categorical_crossentropy: 16.8574 - lr: 0.0100\n",
            "Epoch 60/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 1.7935 - categorical_crossentropy: 1.7935 - val_loss: 17.2237 - val_categorical_crossentropy: 17.2237 - lr: 0.0100\n",
            "Epoch 61/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 1.7371 - categorical_crossentropy: 1.7371 - val_loss: 17.3118 - val_categorical_crossentropy: 17.3118 - lr: 0.0100\n",
            "Epoch 62/70\n",
            "37/37 [==============================] - 9s 238ms/step - loss: 1.6598 - categorical_crossentropy: 1.6598 - val_loss: 17.5770 - val_categorical_crossentropy: 17.5770 - lr: 0.0100\n",
            "Epoch 63/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 1.6405 - categorical_crossentropy: 1.6405 - val_loss: 18.1507 - val_categorical_crossentropy: 18.1507 - lr: 0.0100\n",
            "Epoch 64/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 1.5812 - categorical_crossentropy: 1.5812 - val_loss: 18.6881 - val_categorical_crossentropy: 18.6881 - lr: 0.0100\n",
            "Epoch 65/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 1.5383 - categorical_crossentropy: 1.5383 - val_loss: 18.3207 - val_categorical_crossentropy: 18.3207 - lr: 0.0100\n",
            "Epoch 66/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 1.5903 - categorical_crossentropy: 1.5903 - val_loss: 18.2090 - val_categorical_crossentropy: 18.2090 - lr: 0.0100\n",
            "Epoch 67/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 1.4959 - categorical_crossentropy: 1.4959 - val_loss: 18.9095 - val_categorical_crossentropy: 18.9095 - lr: 0.0100\n",
            "Epoch 68/70\n",
            "37/37 [==============================] - 9s 237ms/step - loss: 1.4663 - categorical_crossentropy: 1.4663 - val_loss: 19.2520 - val_categorical_crossentropy: 19.2520 - lr: 0.0100\n",
            "Epoch 69/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 1.3884 - categorical_crossentropy: 1.3884 - val_loss: 19.8129 - val_categorical_crossentropy: 19.8129 - lr: 0.0100\n",
            "Epoch 70/70\n",
            "37/37 [==============================] - 8s 229ms/step - loss: 1.2992 - categorical_crossentropy: 1.2992 - val_loss: 20.5103 - val_categorical_crossentropy: 20.5103 - lr: 0.0100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelGRU.save(\"/content/drive/MyDrive/Colab Notebooks/modelLM-GRU.h5\")"
      ],
      "metadata": {
        "id": "WWlDKVNhQ35F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e62fbec-1d90-41d7-ec7a-3988ebf0d9bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = perplexity(modelGRU, x_sequences[:100], y_sequences[:100], vocab_size, embedding_matrix)\n",
        "print(\"Perplejidad del modelo:\", perplexity)"
      ],
      "metadata": {
        "id": "Rh_ytLjBp497"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DEEhCjrxQ3WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generación\n",
        "Se además de evaluar la metrica de perplejidad se probaron las capacidades de generacion de los 3 modelos entrenados. En este caso se probaron 2 funciones distintas, por un lado se tomó una implementación para el algoritmo \"Greedy Search\" y por otro \"Beam Search\".\n",
        "\n",
        "Una fuente que resultó útil para entenderlos fue: https://medium.com/@jessica_lopez/understanding-greedy-search-and-beam-search-98c1e3cd821d\n",
        "\n",
        "Las implementaciones presentadas en este trabajo fueron tomadas del grupo Basili-Wahle, quienes no solo accedieron a su uso sino que tambien colaboraron a su vez en entender algunas cuestiones particulares a las mismas."
      ],
      "metadata": {
        "id": "G-aWG1YX4B_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corremos las funciones sobre el modelo obtenido con LSTM, que fue el que mejores metricas de Loss obtuvo."
      ],
      "metadata": {
        "id": "EqYTMFSypePW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Greedy Search con Arg-Max"
      ],
      "metadata": {
        "id": "qcM3lotldfV-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy(seed_phrase, token, model, pred_len=25, max_len=500, stopper=\"> sep\"):\n",
        "  stop_token = token.texts_to_sequences([stopper])[0]\n",
        "  seed_text = token.texts_to_sequences([seed_phrase])[0]\n",
        "  pred_arr = []\n",
        "\n",
        "  for _ in range(pred_len):\n",
        "    # Concatenamos y paddeamos\n",
        "    aux = np.concatenate((seed_text, pred_arr))\n",
        "    padded = pad_sequences([aux], maxlen=max_len)\n",
        "\n",
        "    # Predecimos\n",
        "    pred_idx = np.argmax(model.predict(padded, verbose=0)[0])\n",
        "\n",
        "    if pred_idx in stop_token:  # La prediccion hasta un stop_char\n",
        "      break\n",
        "\n",
        "    pred_arr = np.append(pred_arr, [int(pred_idx)])\n",
        "\n",
        "\n",
        "  return token.sequences_to_texts([pred_arr])[0]"
      ],
      "metadata": {
        "id": "r_OA_O2o04ji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed= \"< el siguiente\"\n",
        "prediction = greedy(seed, token, modelLSTM, pred_len=10)\n",
        "print(seed, prediction)"
      ],
      "metadata": {
        "id": "fZ156eHndttN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3055776c-1eb7-4be7-bf37-3e57f7cfba3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "< el siguiente conseguido ya no estaban fatiga de la puerta y allí en el mismo tren las puertas a lo alto y además había pensado con fuerza\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Greedy Search + Temperatura"
      ],
      "metadata": {
        "id": "3ywLKXBFdwcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def greedyTemp(seed_phrase, token, model, temp=1, pred_len=25, max_len=500, stopper=[\">\", \"sep\"]):\n",
        "  stop_token = token.texts_to_sequences(stopper)[0]\n",
        "  seed_text = token.texts_to_sequences([seed_phrase])[0]\n",
        "  pred_arr = []\n",
        "\n",
        "  for _ in range(pred_len):\n",
        "    # Concatenamos y paddeamos\n",
        "    aux = np.concatenate((seed_text, pred_arr))\n",
        "    padded = pad_sequences([aux], maxlen=max_len)\n",
        "\n",
        "    # Predecimos considerando temperatura y elegimos de forma semialeatoria\n",
        "    probs = (model.predict(padded, verbose=0)[0])**(1/temp)\n",
        "    pred_idx = random.choices(range(len(probs)), weights=probs, k=1)\n",
        "\n",
        "    if pred_idx in stop_token:\n",
        "      break\n",
        "\n",
        "    # Agregamos el nuevo token a la prediccion\n",
        "    pred_arr = np.append(pred_arr, [pred_idx])\n",
        "\n",
        "  return token.sequences_to_texts([pred_arr])[0]"
      ],
      "metadata": {
        "id": "KYabpkGidxod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comenzamos con un valor de temperatura relativamente conservador"
      ],
      "metadata": {
        "id": "v269au9flb7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed= \"< el siguiente\"\n",
        "prediction = greedyTemp(seed, token, modelLSTM, temp=1.25, pred_len=10)\n",
        "print(seed, prediction)\n"
      ],
      "metadata": {
        "id": "vd9seoojd1_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee8f7de-f182-439a-890b-8986b5fceecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "< el siguiente agudo de la calle se ponía fuera las tardes y otra vez bueno gregorio lo mantenía la nueva cosa que le pasaría si se la\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aumentamos su valor.."
      ],
      "metadata": {
        "id": "TDfW0GlOlg3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed= \"< el siguiente\"\n",
        "prediction = greedyTemp(seed, token, modelLSTM, temp=2.25, pred_len=10)\n",
        "print(seed, prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJkWLiIHlHyu",
        "outputId": "ccb51d51-6a9d-4279-a328-43f4378fad83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "< el siguiente regazo con su hermana compasivo en la habitación de mucho direcciones para levantar porque su atención huida cien menos semejante necesario ponía mucho que ver\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si bien algunas partes parecieran tener sentido, se degrada el significado general. Se aprecian entonces casos de \"alucinaciones\""
      ],
      "metadata": {
        "id": "Qz-G1kq4ljb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed= \"< el siguiente\"\n",
        "prediction = greedyTemp(seed, token, modelLSTM, temp=0.5, pred_len=10)\n",
        "print(seed, prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6ZGLJc5lMXN",
        "outputId": "d2b0d53f-ddf2-4646-dcc9-cb4995972f9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "< el siguiente conseguido ya no estaban fatiga de la puerta de la puerta pero ahora no podía ocurrirle alguna el año acaso y volvió a levantarla mirando\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notamos que al bajar la temperatura, disminuyen los \"delirios\" pero empiezan a haber signos de loops."
      ],
      "metadata": {
        "id": "yIVwTRHqlTQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Stochastic Beam Search"
      ],
      "metadata": {
        "id": "GaPeQUw9d4dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def stochastic_beam_search(seed_phrase, token, n_beam=3, temp=1.0, pred_len=20):\n",
        "    seqs = token.texts_to_sequences([seed_phrase])\n",
        "    probs = [1]\n",
        "\n",
        "    for paso in range(pred_len):\n",
        "        new_seqs = []\n",
        "        new_probs = []\n",
        "\n",
        "        for i in range(len(seqs)):\n",
        "            padded = pad_sequences([seqs[i]], maxlen=max_len)\n",
        "            # Generar prediccion y aplicar temp\n",
        "            pred_probs = (modelLSTM.predict(padded, verbose=0)[0])**(1/temp)\n",
        "\n",
        "            # Elegir N opciones en base a sus probs\n",
        "            pred_idx = random.choices(range(len(pred_probs)), weights=pred_probs, k=n_beam)\n",
        "\n",
        "            # Appendear token predichos y sus probs calculadas\n",
        "            for idx in pred_idx:\n",
        "              new_seqs.append(seqs[i]+[idx])\n",
        "              new_probs.append(probs[i]*pred_probs[idx])\n",
        "\n",
        "        # Actualizamos\n",
        "        seqs = new_seqs\n",
        "        probs = new_probs\n",
        "\n",
        "    likely_idx = probs.index(max(probs)) # Me quedo con la opcion mas probable\n",
        "\n",
        "    #Devuelvo la prediccion (sin la seed) en formato texto\n",
        "    return token.sequences_to_texts([seqs[likely_idx]])[0]"
      ],
      "metadata": {
        "id": "zdPjBSRQd-Om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valores iniciales.."
      ],
      "metadata": {
        "id": "YdAtRz4Mow4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed= \"< el siguiente\"\n",
        "prediction = stochastic_beam_search(seed, token, n_beam=3, temp=1, pred_len=8)\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "4xwt-eq4eBjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nuevamente cambiamos la temperatura"
      ],
      "metadata": {
        "id": "OyydDWdDou1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seed= \"< el siguiente\"\n",
        "prediction = stochastic_beam_search(seed, modelLSTM, n_beam=3, temp=2, pred_len=8)      #Variamos la temperatura\n",
        "print(prediction)"
      ],
      "metadata": {
        "id": "QyIhDnWreB52"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}